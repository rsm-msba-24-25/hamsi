---
title: "A Replication of Karlan and List (2007)"
author: "Hamsavi Krishnan"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale field experiment to test how different charitable appeals influence giving behavior. They sent approximately **50,000 fundraising letters** to potential donors, randomly assigning recipients to receive one of several types of letters. These included:

- A **standard fundraising letter** (control),
- A letter that mentioned a **1:1 matching donation**,
- A **2:1 match** offer,
- And a **3:1 match** offer.

The researchers measured both whether recipients made a donation and the amount donated. Their findings, published in the *American Economic Review* (2007), provide key insights into how **framing and incentives** can affect philanthropic behavior.

This project replicates part of that analysis using the publicly available dataset and aims to evaluate whether matched donations not only increase participation rates, but also the size of donations.

---
## Data
The dataset used in this replication was obtained from the Karlan & List (2007) study and loaded into R using the `haven` package. The data includes donation behavior, match treatment assignments, and demographic information for each recipient.

:::: {.callout-note collapse="true"}
### Loading Data
```{r}
library(haven)
data <- read_dta("C:/Users/krish/hamsavi/blog/project3/karlan_list_2007.dta")
```

::::

:::: {.callout-note collapse="true"}
### Description



```{r}

#_todo: Read the data into R/Python and describe the data_
## Load libraries
library(haven)
library(dplyr)
library(ggplot2)

# Read the data
data <- read_dta("karlan_list_2007.dta")

# View structure of the dataset
str(data)

data %>%
  group_by(treatment) %>%
  summarise(
    response_rate = mean(gave),
    avg_donation = mean(amount),
    n = n()
  )

```
::::


:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::
:::: {.callout-note collapse="true"}
## Balance Test

To validate the success of the random assignment in this field experiment, we compare characteristics of the treatment and control groups **before any intervention**. This ensures that the groups were balanced at baseline and that any post-treatment differences can be interpreted **causally**.

We focus on four pre-treatment variables:
- `mrm2` — *Months since last donation*
- `hpa` — *Highest previous contribution*
- `years` — *Years since first donation*
- `freq` — *Number of previous donations*

For each, we:
- Conduct a **t-test** comparing means between treatment and control
- Run a **linear regression** of the form: `variable ~ treatment`

This balance check corresponds to the purpose of **Table 1 in Karlan & List (2007)**, which confirms that randomization produced statistically comparable groups at baseline.

```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show test results"
#| message: false
#| warning: false

library(dplyr)
library(broom)
library(knitr)

# Variables to test
vars <- c("mrm2", "hpa", "years", "freq")

# Run t-tests and regressions
t_test_results <- list()
lm_results <- list()

for (var in vars) {
  t_test_results[[var]] <- tidy(t.test(data[[var]] ~ data$treatment, var.equal = TRUE)) %>%
    select(statistic, p.value, estimate1, estimate2) %>%
    mutate(variable = var)

  lm_results[[var]] <- tidy(lm(as.formula(paste(var, "~ treatment")), data = data)) %>%
    filter(term == "treatment") %>%
    select(term, estimate, statistic, p.value) %>%
    mutate(variable = var)
}

# Combine into tables
t_test_df <- bind_rows(t_test_results)
lm_df <- bind_rows(lm_results)

# Display results
kable(t_test_df, caption = "T-Test Results: Mean Comparison Between Treatment and Control")
kable(lm_df, caption = "Regression Results: Variable ~ Treatment")

```

### Commentary on Results

The t-tests show no statistically significant differences between the treatment and control groups across all four pre-treatment variables — all p-values are well above the 0.05 threshold. The regression results reinforce this, with all coefficients on the `treatment` variable being small and statistically insignificant.

### Comparison to Table 1 in Karlan & List (2007)

Table 1 in the *Karlan & List (2007)* paper presents descriptive statistics for both groups prior to intervention. Its purpose is to **validate the randomization mechanism** by showing that observable characteristics were balanced.

In this replication, we used both **t-tests** and **regressions** to assess balance on the same kinds of baseline variables. Our findings confirm that:
- No variable tested showed a statistically significant difference at the 95% confidence level.
- This supports the idea that **randomization worked**, and we can attribute post-treatment differences to the treatment itself (e.g., letter type), not to pre-existing group differences.

### Why Table 1 Matters

Table 1 is essential in experimental work because:
- It reassures the reader that the experimental design was sound.
- It strengthens the **causal interpretation** of post-treatment outcomes.
- It enhances **replicability and transparency** by showing descriptive stats up front.

This balance check gives us confidence to move forward and analyze treatment effects without concerns of baseline bias.

::::
:::: {.callout-note collapse="true"}
## Experimental Results

Having established that the treatment and control groups were balanced at baseline, we now examine the impact of the different fundraising appeals on donation behavior. Specifically, we assess:

- Whether receiving a matched donation offer increases the likelihood of donating.
- Whether it affects the amount donated.
- Whether the match size (e.g., 1:1 vs. 2:1 or 3:1) influences giving behavior.

We begin by analyzing the **response rate** — the proportion of individuals who made any donation.

::::

::: {.callout-note collapse="true"}
### Charitable Contribution Made

We begin by evaluating whether receiving a matched donation offer influences the **likelihood of making a charitable contribution**. First, we calculate the proportion of individuals who donated in each group (treatment vs. control) and display the results in a bar chart.
```{r}
#| code-fold: true
#| code-summary: "Show code"
#| fig-cap: "Proportion of Donors in Treatment vs Control Groups"
#| fig-width: 6
#| fig-height: 5
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)
library(scales)

donation_rates <- data %>%
  group_by(treatment) %>%
  summarise(Proportion = mean(gave, na.rm = TRUE)) %>%
  mutate(Group = ifelse(treatment == 1, "Treatment", "Control"))

ggplot(donation_rates, aes(x = Group, y = Proportion, fill = Group)) +
  geom_col(width = 0.5) +
  labs(
    title = "Proportion of People Who Donated",
    x = "Group",
    y = "Proportion Donated"
  ) +
  scale_y_continuous(
    labels = percent_format(accuracy = 1),
    breaks = seq(0, 0.03, by = 0.01),
    limits = c(0, 0.03)
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```
The chart shows that the **treatment group**, who received a matched donation appeal, donated at a higher rate than the control group. While the difference may seem modest in absolute terms, it provides early evidence that a matching offer **encourages donation behavior**.


### Likelihood of Donation: T-Test and Linear Regression

We now conduct a **t-test** and a **bivariate linear regression** to statistically test whether treatment assignment increases donation likelihood. This replicates Table 2a Panel A in *Karlan & List (2007)*.


```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

library(broom)
library(knitr)

# T-test
gave_ttest <- t.test(gave ~ treatment, data = data, var.equal = TRUE)
# Regression
gave_lm <- lm(gave ~ treatment, data = data)

# Tidy and present
kable(tidy(gave_ttest), caption = "T-Test: Likelihood of Donation by Treatment Group")
kable(tidy(gave_lm), caption = "Regression: gave ~ treatment")
```
Both models show that individuals in the **treatment group** were significantly more likely to donate than those in the control group. This highlights how **psychological framing**, such as mentioning a match, can motivate giving behavior — even when the match amount is unspecified.

### Probit Model: Likelihood of Donation

To strengthen our results, we estimate a **probit regression model** — a nonlinear model commonly used for binary outcomes — to replicate **Table 3, Column 1** of the original paper.

```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

# Probit model
probit_model <- glm(gave ~ treatment, family = binomial(link = "probit"), data = data)
probit_summary <- tidy(probit_model)

# Output formatted
kable(probit_summary, caption = "Probit Regression: gave ~ treatment")
```
The coefficient on the **treatment variable** is positive and statistically significant, consistent with earlier findings. The intercept, although reported as zero due to rounding, is highly significant — confirming a **non-zero baseline probability of donation**.

This confirms the original study’s conclusion: **matching appeals increase the probability of donation**, and this effect holds under both linear and nonlinear modeling frameworks.
:::




::: {.callout-note collapse="true"}
### Differences Between Match Rates

In this section, we assess whether offering a **larger match ratio** (e.g., 2:1 or 3:1) increases the likelihood of a donation compared to the baseline 1:1 match offer. This analysis tests the claim in Karlan & List (2007) that **"larger match ratios do not lead to higher response rates"** (page 8).
```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

library(dplyr)
library(broom)
library(knitr)

# T-tests: compare response rates across match levels
result_2v1 <- tidy(t.test(gave ~ ratio2, data = data %>% filter(ratio == 1 | ratio2 == 1)))
result_3v1 <- tidy(t.test(gave ~ ratio3, data = data %>% filter(ratio == 1 | ratio3 == 1)))

# Display formatted tables
kable(result_2v1, caption = "T-Test: 2:1 Match vs 1:1 Match")
kable(result_3v1, caption = "T-Test: 3:1 Match vs 1:1 Match")
```
The t-tests compare the likelihood of donating between different match ratios:

- The **2:1 vs 1:1** comparison shows [insert result here].
- The **3:1 vs 1:1** comparison shows [insert result here].

These results provide **no evidence** that higher match ratios significantly increase donation rates. This aligns with the authors’ conclusion that **larger match offers do not meaningfully change behavior beyond the presence of a match itself.**

### Visualizing Donation Rates by Match Ratio
We now visualize the proportion of donors in each match ratio condition.
```{r}
#| code-fold: true
#| code-summary: "Show code"
#| fig-cap: "Donation Rate by Match Ratio (1:1, 2:1, 3:1)"
#| fig-width: 6
#| fig-height: 5
#| message: false
#| warning: false

data %>%
  filter(ratio == 1 | ratio2 == 1 | ratio3 == 1) %>%
  mutate(MatchRatio = case_when(
    ratio3 == 1 ~ "3:1",
    ratio2 == 1 ~ "2:1",
    ratio == 1  ~ "1:1"
  )) %>%
  group_by(MatchRatio) %>%
  summarise(ResponseRate = mean(gave)) %>%
  ggplot(aes(x = MatchRatio, y = ResponseRate, fill = MatchRatio)) +
  geom_col(width = 0.6) +
  labs(title = "Donation Rate by Match Ratio", y = "Proportion Donated", x = "Match Ratio") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(legend.position = "none")
```
### Regression: Match Ratio Effects Within Treatment Group

To confirm the findings statistically, we regress donation probability on dummy variables for each match ratio. This regression is limited to the **treatment group**, where match ratio variation was introduced.

```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

# Create dummies and filter to matched treatment groups
treat_data <- data %>%
  filter(treatment == 1, ratio %in% c(1, 2, 3)) %>%
  mutate(
    ratio1 = ifelse(ratio == 1, 1, 0),
    ratio2 = ifelse(ratio2 == 1, 1, 0),
    ratio3 = ifelse(ratio3 == 1, 1, 0)
  )

# Regression (1:1 match is reference)
model_match_treat <- lm(gave ~ ratio2 + ratio3, data = treat_data)
kable(tidy(model_match_treat), caption = "Regression: Effect of Match Ratio on Donation Likelihood (Treatment Only)")
```
The regression results confirm the t-test findings: neither the **2:1** nor the **3:1** match rate produced a **statistically significant increase** in donation rates compared to the baseline **1:1** match.

This suggests that **increasing the match multiplier does not yield additional behavioral change** — what matters most is simply offering a match.

### Manual Difference Check: Data and Model Coefficients

To reinforce our findings, we calculate response rate differences both **directly from the data** and **using the regression coefficients**.

```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

# Grouped response rates
match_only <- treat_data
response_rates <- match_only %>%
  mutate(match_ratio = case_when(
    ratio == 1 ~ "1:1",
    ratio2 == 1 ~ "2:1",
    ratio3 == 1 ~ "3:1"
  )) %>%
  group_by(match_ratio) %>%
  summarise(ResponseRate = mean(gave), n = n())

# Manual differences
rate_2v1 <- response_rates$ResponseRate[response_rates$match_ratio == "2:1"] -
            response_rates$ResponseRate[response_rates$match_ratio == "1:1"]

rate_3v2 <- response_rates$ResponseRate[response_rates$match_ratio == "3:1"] -
            response_rates$ResponseRate[response_rates$match_ratio == "2:1"]

# Coefficients from regression model
reg_results <- tidy(lm(gave ~ ratio2 + ratio3, data = match_only))
coef_2v1 <- reg_results$estimate[reg_results$term == "ratio2"]
coef_3v2 <- reg_results$estimate[reg_results$term == "ratio3"] - reg_results$estimate[reg_results$term == "ratio2"]

# Output
kable(data.frame(rate_2v1, rate_3v2, coef_2v1, coef_3v2),
      caption = "Match Rate Differences: Manual vs Regression-Based")
```

The table above confirms that:
- The **2:1 vs 1:1** difference is small in both the data and regression.
- The **3:1 vs 2:1** difference is nearly zero or even slightly negative.

These findings reinforce the idea that **increasing match size has little to no marginal effect** on giving behavior.
:::

::: {.callout-note collapse="true"}
### Size of Charitable Contribution

In this section, we examine whether the treatment affected not only the **likelihood of giving**, but also the **amount donated**. We use a **t-test** and a **bivariate linear regression** to compare average donation amounts between the treatment and control groups.
```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

library(dplyr)
library(broom)
library(knitr)

# T-test: compare donation amounts across full sample
t_test_amount <- t.test(amount ~ treatment, data = data, var.equal = TRUE)
t_test_amount_result <- tidy(t_test_amount)

# Linear regression: amount ~ treatment
lm_amount <- lm(amount ~ treatment, data = data)
lm_amount_result <- tidy(lm_amount)

# Display formatted results
kable(t_test_amount_result, caption = "T-Test: Donation Amount by Treatment Group")
kable(lm_amount_result, caption = "Regression: Donation Amount ~ Treatment")
```

The results indicate that the **average donation amount was slightly higher in the treatment group**, but the difference was **not statistically significant**.

This suggests that while the matched donation offer may encourage more people to donate, it does **not necessarily cause them to donate more money**. In other words, the treatment seems to affect **whether someone donates**, but not **how much** they donate once they do.


### Conditional on Donation

We now repeat the analysis, restricting to **only those individuals who actually donated** (`gave == 1`). This isolates the effect of treatment on the **amount given**, conditional on the decision to donate.

```{r}
#| code-fold: true
#| code-summary: "Show code"
#| output-fold: true
#| output-summary: "Show results"
#| message: false
#| warning: false

# Filter to donors only
donors_only <- data %>% filter(gave == 1)

# Conditional analysis
t_test_donors <- t.test(amount ~ treatment, data = donors_only, var.equal = TRUE)
lm_donors <- lm(amount ~ treatment, data = donors_only)

# Tidy and display
kable(tidy(t_test_donors), caption = "T-Test: Donation Amounts Among Donors Only")
kable(tidy(lm_donors), caption = "Regression: Donation Amount ~ Treatment (Donors Only)")
```

#### Interpretation (Donors Only)

When we condition on giving, the **treatment group still appears to give slightly more**, but again, the difference is **not statistically significant**.

#### Causality Caveat

Importantly, this analysis is **not causal**. Since the treatment may have influenced **who chose to give**, the group of donors in each condition is **not randomly assigned**. As a result, differences in donation amount may be driven by **selection bias**, not the treatment itself.

This analysis helps us understand patterns in donor behavior, but does not permit a causal claim about the impact of treatment on donation size.
:::

::: {.callout-note collapse="true"}
### Conditional on Donation: Effect of Treatment on Donation Amount

In this section, we restrict our analysis to only those individuals who **actually made a donation** (`gave == 1`). We then compare the **distribution and average size of donations** between the treatment and control groups.

This helps answer the question: *Among donors, does receiving a matched appeal influence how much people give?*
```{r}
#| code-fold: true
#| code-summary: "Show code"
#| fig-cap: "Donation Amounts Among Donors: Treatment vs. Control Groups"
#| fig-width: 6
#| fig-height: 5
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)
library(patchwork)

# Filter donors
donors <- data %>% filter(gave == 1)

# Split by group
donors_treat <- donors %>% filter(treatment == 1)
donors_control <- donors %>% filter(treatment == 0)

# Plot for treatment group
p_treat <- ggplot(donors_treat, aes(x = amount)) +
  geom_histogram(binwidth = 5, fill = "#5DA5DA", color = "white") +
  geom_vline(xintercept = mean(donors_treat$amount), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Treatment Group", x = "Donation Amount ($)", y = "Number of Donors") +
  theme_minimal()

# Plot for control group
p_control <- ggplot(donors_control, aes(x = amount)) +
  geom_histogram(binwidth = 5, fill = "#FAA43A", color = "white") +
  geom_vline(xintercept = mean(donors_control$amount), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Control Group", x = "Donation Amount ($)", y = "Number of Donors") +
  theme_minimal()

# Display side-by-side
p_control + p_treat
```

Each histogram above shows the **distribution of donation amounts** for individuals who gave, separated by treatment status. The **red dashed line** represents the **average donation** within each group.

#### Results:
- Both groups show a right-skewed distribution, typical of donation data.
- The treatment group's average donation appears slightly higher, but the shapes of the distributions are quite similar.

#### Interpretation:
While the treatment group may give slightly more on average, this analysis does **not imply causality**. Since we’re conditioning on giving behavior (which itself may be influenced by the treatment), any differences in donation amount could be due to **selection bias** among those who chose to donate.

This section offers insight into the **intensity of giving** among participants but does not allow for a causal interpretation of the treatment effect on donation size.
:::

:::: {.callout-note collapse="true"}
## Simulation Experiment

As a reminder of how the **t-statistic** and **sampling averages** behave under repeated trials, this section uses simulation to demonstrate two fundamental statistical principles: the **Law of Large Numbers** and the **Central Limit Theorem**.

Suppose that the true donation probability is:
- **1.8% (p = 0.018)** for individuals who **do not receive** a matched donation offer, and
- **2.2% (p = 0.022)** for individuals who **do receive** a matched donation offer.

We now simulate repeated draws from these two distributions to see whether the **average difference in giving behavior** converges toward the true difference.

```{r}
#| code-fold: true
#| code-summary: "Show code"
#| fig-cap: "Cumulative Average of Simulated Differences in Donation Amounts"
#| fig-width: 6
#| fig-height: 5
#| message: false
#| warning: false

set.seed(123)
library(dplyr)
library(ggplot2)

# Simulate 100,000 draws from control (Bernoulli with p = 0.018)
control_draws <- rbinom(100000, size = 1, prob = 0.018)

# Simulate 10,000 draws from treatment (Bernoulli with p = 0.022)
treatment_draws <- rbinom(10000, size = 1, prob = 0.022)

# Compute 10,000 differences between paired draws
differences <- treatment_draws - control_draws[1:10000]

# Compute cumulative average
cumulative_avg <- cumsum(differences) / seq_along(differences)

# True difference
true_diff <- 0.022 - 0.018

# Set symmetrical y-axis limits around 0
ylim_range <- max(abs(c(min(cumulative_avg), max(cumulative_avg))))
y_limits <- c(-ylim_range, ylim_range)

# Plot the cumulative average
ggplot(data.frame(draw = 1:10000, cumulative_avg = cumulative_avg),
       aes(x = draw, y = cumulative_avg)) +
  geom_line(color = "#3A87B9", size = 1) +
  geom_hline(yintercept = 0, color = "gray50", linetype = "solid") +
  geom_hline(yintercept = true_diff, color = "#D73027", linetype = "dashed", size = 1) +
  labs(
    title = "Cumulative Average of Simulated Differences in Donation Amounts",
    x = "Number of Simulations",
    y = "Cumulative Average Difference"
  ) +
  coord_cartesian(ylim = y_limits) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(color = "gray20")
  )
```
### Interpretation

The chart above shows how the **cumulative average** of 10,000 simulated differences in donation rates behaves as more samples are drawn. Each point on the line represents the running average of the difference between simulated treatment and control donations.

- The **red dashed line** represents the true difference in giving probability: 0.004 (i.e., 2.2% - 1.8%).
- The **gray solid line** at zero shows the null effect (no difference).

As the number of draws increases, the cumulative average **quickly converges toward the true difference**, demonstrating the **Law of Large Numbers**: with enough repeated trials, the sample mean converges to the population mean.

This simulation offers intuitive insight into why larger samples lead to more reliable estimates — a foundation of modern statistical inference.
::::

:::: {.callout-note collapse="true"}
## Central Limit Theorem

This section demonstrates the **Central Limit Theorem** through simulation. We repeatedly sample from the treatment and control groups and calculate the difference in average donation amounts across four different sample sizes: 50, 200, 500, and 1000.

For each sample size:
- We simulate 1,000 experiments.
- In each, we draw `n` random observations from both the treatment and control groups (donors only).
- We calculate the difference in means and record it.
- We then plot the histogram of those 1,000 differences.

These histograms allow us to visualize how the **sampling distribution** changes as sample size increases.
```{r}
#| code-fold: true
#| code-summary: "Show code"
#| fig-cap: "Sampling Distribution of Mean Differences Across Sample Sizes"
#| fig-width: 6
#| fig-height: 5
#| message: false
#| warning: false

set.seed(123)
library(dplyr)
library(ggplot2)
library(patchwork)

# Filter to donors only
donors <- data %>% filter(gave == 1)

# Extract treatment and control donations
control <- donors %>% filter(treatment == 0) %>% pull(amount)
treatment <- donors %>% filter(treatment == 1) %>% pull(amount)

# Calculate true mean difference
true_diff <- mean(treatment) - mean(control)

# Simulation function
simulate_differences <- function(n, reps = 1000) {
  replicate(reps, {
    mean(sample(treatment, n, replace = TRUE)) -
      mean(sample(control, n, replace = TRUE))
  })
}

# Simulations
diffs_50 <- simulate_differences(50)
diffs_200 <- simulate_differences(200)
diffs_500 <- simulate_differences(500)
diffs_1000 <- simulate_differences(1000)

# Prettier histogram plot function
plot_histogram <- function(diffs, n, binwidth = 1.5) {
  ggplot(data.frame(diff = diffs), aes(x = diff)) +
    geom_histogram(aes(y = ..density.., fill = ..x..), binwidth = binwidth, color = "white") +
    scale_fill_gradient(low = "#B3DDF2", high = "#3A87B9") +  # soft blue gradient
    geom_vline(xintercept = 0, color = "red", linetype = "dashed", linewidth = 1) +
    geom_vline(xintercept = true_diff, color = "darkgreen", linetype = "dotted", linewidth = 1) +
    labs(
      title = paste("Sample Size:", n),
      x = "Difference in Mean\nDonations (Treatment - Control)",
      y = "Density"
    ) +
    xlim(-10, 10) +
    theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      axis.title = element_text(face = "bold", size = 11),
      axis.text = element_text(size = 9, color = "gray20"),
      legend.position = "none"
    )
}

# Generate 4 prettier plots
p50 <- plot_histogram(diffs_50, 50)
p200 <- plot_histogram(diffs_200, 200)
p500 <- plot_histogram(diffs_500, 500)
p1000 <- plot_histogram(diffs_1000, 1000)

# Combine into 2x2 layout
(p50 | p200) / (p500 | p1000)

```
The plots above illustrate how the **sampling distribution of the mean difference** becomes increasingly concentrated as the sample size increases.

- For **n = 50**, the distribution is wide and noisy — zero lies comfortably within the range of common outcomes.
- As **sample size grows**, the distribution narrows.
- By **n = 1000**, the distribution is tightly centered around the **true treatment effect** (green dotted line), and zero (red dashed line) is clearly in the tail.

This pattern is a visual demonstration of the **Central Limit Theorem**: as sample size increases, the distribution of sample means approaches a normal distribution centered at the true mean. It also shows why **larger sample sizes improve statistical power** in experiments like this one.

::::

