[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\n\n\nHamsavi Krishnan\n\n\nMay 28, 2025\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nHamsavi Krishnan\n\n\nMay 28, 2025\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nHamsavi Krishnan\n\n\nMay 7, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project3/index.html",
    "href": "blog/project3/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale field experiment to test how different charitable appeals influence giving behavior. They sent approximately 50,000 fundraising letters to potential donors, randomly assigning recipients to receive one of several types of letters. These included:\n\nA standard fundraising letter (control),\nA letter that mentioned a 1:1 matching donation,\nA 2:1 match offer,\nAnd a 3:1 match offer.\n\nThe researchers measured both whether recipients made a donation and the amount donated. Their findings, published in the American Economic Review (2007), provide key insights into how framing and incentives can affect philanthropic behavior.\nThis project replicates part of that analysis using the publicly available dataset and aims to evaluate whether matched donations not only increase participation rates, but also the size of donations."
  },
  {
    "objectID": "blog/project3/index.html#introduction",
    "href": "blog/project3/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale field experiment to test how different charitable appeals influence giving behavior. They sent approximately 50,000 fundraising letters to potential donors, randomly assigning recipients to receive one of several types of letters. These included:\n\nA standard fundraising letter (control),\nA letter that mentioned a 1:1 matching donation,\nA 2:1 match offer,\nAnd a 3:1 match offer.\n\nThe researchers measured both whether recipients made a donation and the amount donated. Their findings, published in the American Economic Review (2007), provide key insights into how framing and incentives can affect philanthropic behavior.\nThis project replicates part of that analysis using the publicly available dataset and aims to evaluate whether matched donations not only increase participation rates, but also the size of donations."
  },
  {
    "objectID": "blog/project3/index.html#data",
    "href": "blog/project3/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\nThe dataset used in this replication was obtained from the Karlan & List (2007) study and loaded into R using the haven package. The data includes donation behavior, match treatment assignments, and demographic information for each recipient.\n\n\n\n\n\n\nLoading Data\n\n\n\n\n\n\nlibrary(haven)\ndata &lt;- read_dta(\"C:/Users/krish/hamsavi/blog/project3/karlan_list_2007.dta\")\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\n#_todo: Read the data into R/Python and describe the data_\n## Load libraries\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Read the data\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n# View structure of the dataset\nstr(data)\n\ntibble [50,083 × 51] (S3: tbl_df/tbl/data.frame)\n $ treatment         : num [1:50083] 0 0 1 1 1 0 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Treatment\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ control           : num [1:50083] 1 1 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Control\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ratio             : dbl+lbl [1:50083] 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1, 3, 3...\n   ..@ label       : chr \"Match ratio\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num 0\n   .. ..- attr(*, \"names\")= chr \"Control\"\n $ ratio2            : num [1:50083] 0 0 0 0 0 0 0 1 1 0 ...\n  ..- attr(*, \"label\")= chr \"2:1 match ratio\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ratio3            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"3:1 match ratio\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size              : dbl+lbl [1:50083] 0, 0, 3, 4, 2, 0, 1, 3, 4, 1, 4, 2, 0, 1, 0, 4, 1, 4...\n   ..@ label       : chr \"Match threshold\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num [1:5] 0 1 2 3 4\n   .. ..- attr(*, \"names\")= chr [1:5] \"Control\" \"$25,000\" \"$50,000\" \"$100,000\" ...\n $ size25            : num [1:50083] 0 0 0 0 0 0 1 0 0 1 ...\n  ..- attr(*, \"label\")= chr \"$25,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size50            : num [1:50083] 0 0 0 0 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"$50,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ size100           : num [1:50083] 0 0 1 0 0 0 0 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"$100,000 match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ sizeno            : num [1:50083] 0 0 0 1 0 0 0 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Unstated match threshold\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ask               : dbl+lbl [1:50083] 0, 0, 1, 1, 1, 0, 3, 3, 2, 2, 1, 3, 0, 2, 0, 1, 2, 3...\n   ..@ label       : chr \"Suggested donation amount\"\n   ..@ format.stata: chr \"%9.0g\"\n   ..@ labels      : Named num [1:4] 0 1 2 3\n   .. ..- attr(*, \"names\")= chr [1:4] \"Control\" \"1x\" \"1.25x\" \"1.50x\"\n $ askd1             : num [1:50083] 0 0 1 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ askd2             : num [1:50083] 0 0 0 0 0 0 0 0 1 1 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was 1.25 x highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ askd3             : num [1:50083] 0 0 0 0 0 0 1 1 0 0 ...\n  ..- attr(*, \"label\")= chr \"Suggested donation was 1.50 x highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ ask1              : num [1:50083] 55 25 55 55 35 95 125 75 250 150 ...\n  ..- attr(*, \"label\")= chr \"Highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ ask2              : num [1:50083] 70 35 70 70 45 120 160 95 315 190 ...\n  ..- attr(*, \"label\")= chr \"1.25 x highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ ask3              : num [1:50083] 85 50 85 85 55 145 190 120 375 225 ...\n  ..- attr(*, \"label\")= chr \"1.50 x highest previous contribution (for suggestion)\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ amount            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Dollars given\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ gave              : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Gave anything\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ amountchange      : num [1:50083] -45 -25 -50 -25 -15 -45 -50 -65 -100 -125 ...\n  ..- attr(*, \"label\")= chr \"Change in amount given\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2fc\"\n $ hpa               : num [1:50083] 45 25 50 50 25 90 100 65 200 125 ...\n  ..- attr(*, \"label\")= chr \"Highest previous contribution\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2fc\"\n $ ltmedmra          : num [1:50083] 0 1 0 1 1 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Small prior donor: last gift was less than median $35\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ freq              : num [1:50083] 2 2 3 15 42 20 12 13 28 4 ...\n  ..- attr(*, \"label\")= chr \"Number of prior donations\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ years             : num [1:50083] 4 3 2 8 95 10 8 16 19 7 ...\n  ..- attr(*, \"label\")= chr \"Number of years since initial donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ year5             : num [1:50083] 0 0 0 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"At least 5 years since initial donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ mrm2              : num [1:50083] 31 5 6 1 24 3 4 4 6 35 ...\n  ..- attr(*, \"label\")= chr \"Number of months since last donation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ dormant           : num [1:50083] 1 0 0 0 1 0 0 0 0 1 ...\n  ..- attr(*, \"label\")= chr \"Already donated in 2005\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ female            : num [1:50083] 0 0 0 0 1 0 1 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Female\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ couple            : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Couple\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ state50one        : num [1:50083] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"State tag: 1 for one observation of each of 50 states; 0 otherwise\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ nonlit            : num [1:50083] 5 0 3 1 1 0 0 4 1 4 ...\n  ..- attr(*, \"label\")= chr \"Nonlitigation\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ cases             : num [1:50083] 4 2 1 2 1 0 1 3 1 3 ...\n  ..- attr(*, \"label\")= chr \"Court cases from state in 2004-5 in which organization was involved\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ statecnt          : num [1:50083] 4.5 2.98 9.61 3.28 2.3 ...\n  ..- attr(*, \"label\")= chr \"Percent of sample from state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ stateresponse     : num [1:50083] 0.0199 0.0261 0.023 0.0207 0.0156 ...\n  ..- attr(*, \"label\")= chr \"Proportion of sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponset    : num [1:50083] 0.0195 0.0278 0.0222 0.0247 0.017 ...\n  ..- attr(*, \"label\")= chr \"Proportion of treated sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponsec    : num [1:50083] 0.0208 0.0225 0.0247 0.0127 0.0129 ...\n  ..- attr(*, \"label\")= chr \"Proportion of control sample from the state who gave\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ stateresponsetminc: num [1:50083] -0.0013 0.00534 -0.00258 0.01202 0.00408 ...\n  ..- attr(*, \"label\")= chr \"stateresponset - stateresponsec\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ perbush           : num [1:50083] 0.49 0.465 0.408 0.465 0.525 ...\n  ..- attr(*, \"label\")= chr \"State vote share for Bush\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ close25           : num [1:50083] 1 0 0 0 0 1 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"State vote share for Bush between 47.5% and 52.5%\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ red0              : num [1:50083] 0 0 0 0 1 1 1 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Red state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ blue0             : num [1:50083] 1 1 1 1 0 0 0 1 0 1 ...\n  ..- attr(*, \"label\")= chr \"Blue state\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ redcty            : num [1:50083] 0 1 0 1 0 1 1 0 1 0 ...\n  ..- attr(*, \"label\")= chr \"Red county\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ bluecty           : num [1:50083] 1 0 1 0 1 0 0 1 0 1 ...\n  ..- attr(*, \"label\")= chr \"Blue county\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n $ pwhite            : num [1:50083] 0.446 NA 0.936 0.888 0.759 ...\n  ..- attr(*, \"label\")= chr \"Proportion white within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ pblack            : num [1:50083] 0.5278 NA 0.0119 0.0108 0.1274 ...\n  ..- attr(*, \"label\")= chr \"Proportion black within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ page18_39         : num [1:50083] 0.318 NA 0.276 0.279 0.442 ...\n  ..- attr(*, \"label\")= chr \"Proportion age 18-39 within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ ave_hh_sz         : num [1:50083] 2.1 NA 2.48 2.65 1.85 ...\n  ..- attr(*, \"label\")= chr \"Average household size within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.2f\"\n $ median_hhincome   : num [1:50083] 28517 NA 51175 79269 40908 ...\n  ..- attr(*, \"label\")= chr \"Median household income within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.0gc\"\n $ powner            : num [1:50083] 0.5 NA 0.722 0.92 0.416 ...\n  ..- attr(*, \"label\")= chr \"Proportion house owner within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ psch_atlstba      : num [1:50083] 0.325 NA 0.193 0.412 0.44 ...\n  ..- attr(*, \"label\")= chr \"Proportion who finished college within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n $ pop_propurban     : num [1:50083] 1 NA 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Proportion of population urban within zip code\"\n  ..- attr(*, \"format.stata\")= chr \"%9.4f\"\n\ndata %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    response_rate = mean(gave),\n    avg_donation = mean(amount),\n    n = n()\n  )\n\n# A tibble: 2 × 4\n  treatment response_rate avg_donation     n\n      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1         0        0.0179        0.813 16687\n2         1        0.0220        0.967 33396\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\nBalance Test\n\n\n\n\n\nTo validate the success of the random assignment in this field experiment, we compare characteristics of the treatment and control groups before any intervention. This ensures that the groups were balanced at baseline and that any post-treatment differences can be interpreted causally.\nWe focus on four pre-treatment variables: - mrm2 — Months since last donation - hpa — Highest previous contribution - years — Years since first donation - freq — Number of previous donations\nFor each, we: - Conduct a t-test comparing means between treatment and control - Run a linear regression of the form: variable ~ treatment\nThis balance check corresponds to the purpose of Table 1 in Karlan & List (2007), which confirms that randomization produced statistically comparable groups at baseline.\n\n\nShow code\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\n\n# Variables to test\nvars &lt;- c(\"mrm2\", \"hpa\", \"years\", \"freq\")\n\n# Run t-tests and regressions\nt_test_results &lt;- list()\nlm_results &lt;- list()\n\nfor (var in vars) {\n  t_test_results[[var]] &lt;- tidy(t.test(data[[var]] ~ data$treatment, var.equal = TRUE)) %&gt;%\n    select(statistic, p.value, estimate1, estimate2) %&gt;%\n    mutate(variable = var)\n\n  lm_results[[var]] &lt;- tidy(lm(as.formula(paste(var, \"~ treatment\")), data = data)) %&gt;%\n    filter(term == \"treatment\") %&gt;%\n    select(term, estimate, statistic, p.value) %&gt;%\n    mutate(variable = var)\n}\n\n# Combine into tables\nt_test_df &lt;- bind_rows(t_test_results)\nlm_df &lt;- bind_rows(lm_results)\n\n# Display results\nkable(t_test_df, caption = \"T-Test Results: Mean Comparison Between Treatment and Control\")\n\n\n\nT-Test Results: Mean Comparison Between Treatment and Control\n\n\nstatistic\np.value\nestimate1\nestimate2\nvariable\n\n\n\n\n-0.1194921\n0.9048860\n12.998142\n13.011828\nmrm2\n\n\n-0.9441476\n0.3450988\n58.960167\n59.597243\nhpa\n\n\n1.1030384\n0.2700158\n6.135914\n6.078365\nyears\n\n\n0.1108930\n0.9117017\n8.047342\n8.035364\nfreq\n\n\n\n\n\nShow code\nkable(lm_df, caption = \"Regression Results: Variable ~ Treatment\")\n\n\n\nRegression Results: Variable ~ Treatment\n\n\nterm\nestimate\nstatistic\np.value\nvariable\n\n\n\n\ntreatment\n0.0136859\n0.1194921\n0.9048860\nmrm2\n\n\ntreatment\n0.6370753\n0.9441476\n0.3450988\nhpa\n\n\ntreatment\n-0.0575492\n-1.1030384\n0.2700158\nyears\n\n\ntreatment\n-0.0119787\n-0.1108930\n0.9117017\nfreq\n\n\n\n\n\n\nCommentary on Results\nThe t-tests show no statistically significant differences between the treatment and control groups across all four pre-treatment variables — all p-values are well above the 0.05 threshold. The regression results reinforce this, with all coefficients on the treatment variable being small and statistically insignificant.\n\n\nComparison to Table 1 in Karlan & List (2007)\nTable 1 in the Karlan & List (2007) paper presents descriptive statistics for both groups prior to intervention. Its purpose is to validate the randomization mechanism by showing that observable characteristics were balanced.\nIn this replication, we used both t-tests and regressions to assess balance on the same kinds of baseline variables. Our findings confirm that: - No variable tested showed a statistically significant difference at the 95% confidence level. - This supports the idea that randomization worked, and we can attribute post-treatment differences to the treatment itself (e.g., letter type), not to pre-existing group differences.\n\n\nWhy Table 1 Matters\nTable 1 is essential in experimental work because: - It reassures the reader that the experimental design was sound. - It strengthens the causal interpretation of post-treatment outcomes. - It enhances replicability and transparency by showing descriptive stats up front.\nThis balance check gives us confidence to move forward and analyze treatment effects without concerns of baseline bias.\n\n\n\n\n\n\n\n\n\n\nExperimental Results\n\n\n\n\n\nHaving established that the treatment and control groups were balanced at baseline, we now examine the impact of the different fundraising appeals on donation behavior. Specifically, we assess:\n\nWhether receiving a matched donation offer increases the likelihood of donating.\nWhether it affects the amount donated.\nWhether the match size (e.g., 1:1 vs. 2:1 or 3:1) influences giving behavior.\n\nWe begin by analyzing the response rate — the proportion of individuals who made any donation.\n\n\n\n\n\n\n\n\n\nCharitable Contribution Made\n\n\n\n\n\nWe begin by evaluating whether receiving a matched donation offer influences the likelihood of making a charitable contribution. First, we calculate the proportion of individuals who donated in each group (treatment vs. control) and display the results in a bar chart.\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\ndonation_rates &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(Proportion = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(Group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\nggplot(donation_rates, aes(x = Group, y = Proportion, fill = Group)) +\n  geom_col(width = 0.5) +\n  labs(\n    title = \"Proportion of People Who Donated\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_y_continuous(\n    labels = percent_format(accuracy = 1),\n    breaks = seq(0, 0.03, by = 0.01),\n    limits = c(0, 0.03)\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nProportion of Donors in Treatment vs Control Groups\n\n\n\n\nThe chart shows that the treatment group, who received a matched donation appeal, donated at a higher rate than the control group. While the difference may seem modest in absolute terms, it provides early evidence that a matching offer encourages donation behavior.\n\nLikelihood of Donation: T-Test and Linear Regression\nWe now conduct a t-test and a bivariate linear regression to statistically test whether treatment assignment increases donation likelihood. This replicates Table 2a Panel A in Karlan & List (2007).\n\n\nShow code\nlibrary(broom)\nlibrary(knitr)\n\n# T-test\ngave_ttest &lt;- t.test(gave ~ treatment, data = data, var.equal = TRUE)\n# Regression\ngave_lm &lt;- lm(gave ~ treatment, data = data)\n\n# Tidy and present\nkable(tidy(gave_ttest), caption = \"T-Test: Likelihood of Donation by Treatment Group\")\n\n\n\nT-Test: Likelihood of Donation by Treatment Group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.0041804\n0.0178582\n0.0220386\n-3.101361\n0.0019274\n50081\n-0.0068223\n-0.0015384\nTwo Sample t-test\ntwo.sided\n\n\n\n\n\nShow code\nkable(tidy(gave_lm), caption = \"Regression: gave ~ treatment\")\n\n\n\nRegression: gave ~ treatment\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0178582\n0.0011007\n16.224643\n0.0000000\n\n\ntreatment\n0.0041804\n0.0013479\n3.101361\n0.0019274\n\n\n\n\n\nBoth models show that individuals in the treatment group were significantly more likely to donate than those in the control group. This highlights how psychological framing, such as mentioning a match, can motivate giving behavior — even when the match amount is unspecified.\n\n\nProbit Model: Likelihood of Donation\nTo strengthen our results, we estimate a probit regression model — a nonlinear model commonly used for binary outcomes — to replicate Table 3, Column 1 of the original paper.\n\n\nShow code\n# Probit model\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = data)\nprobit_summary &lt;- tidy(probit_model)\n\n# Output formatted\nkable(probit_summary, caption = \"Probit Regression: gave ~ treatment\")\n\n\n\nProbit Regression: gave ~ treatment\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.1001412\n0.0233158\n-90.07391\n0.0000000\n\n\ntreatment\n0.0867846\n0.0278785\n3.11296\n0.0018522\n\n\n\n\n\nThe coefficient on the treatment variable is positive and statistically significant, consistent with earlier findings. The intercept, although reported as zero due to rounding, is highly significant — confirming a non-zero baseline probability of donation.\nThis confirms the original study’s conclusion: matching appeals increase the probability of donation, and this effect holds under both linear and nonlinear modeling frameworks.\n\n\n\n\n\n\n\n\n\n\nDifferences Between Match Rates\n\n\n\n\n\nIn this section, we assess whether offering a larger match ratio (e.g., 2:1 or 3:1) increases the likelihood of a donation compared to the baseline 1:1 match offer. This analysis tests the claim in Karlan & List (2007) that “larger match ratios do not lead to higher response rates” (page 8).\n\n\nShow code\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\n\n# T-tests: compare response rates across match levels\nresult_2v1 &lt;- tidy(t.test(gave ~ ratio2, data = data %&gt;% filter(ratio == 1 | ratio2 == 1)))\nresult_3v1 &lt;- tidy(t.test(gave ~ ratio3, data = data %&gt;% filter(ratio == 1 | ratio3 == 1)))\n\n# Display formatted tables\nkable(result_2v1, caption = \"T-Test: 2:1 Match vs 1:1 Match\")\n\n\n\nT-Test: 2:1 Match vs 1:1 Match\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.0018843\n0.0207491\n0.0226334\n-0.965049\n0.3345308\n22225.08\n-0.0057113\n0.0019428\nWelch Two Sample t-test\ntwo.sided\n\n\n\n\n\nShow code\nkable(result_3v1, caption = \"T-Test: 3:1 Match vs 1:1 Match\")\n\n\n\nT-Test: 3:1 Match vs 1:1 Match\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.0019843\n0.0207491\n0.0227334\n-1.015017\n0.3101086\n22215.05\n-0.0058161\n0.0018475\nWelch Two Sample t-test\ntwo.sided\n\n\n\n\n\nThe t-tests compare the likelihood of donating between different match ratios:\n\nThe 2:1 vs 1:1 comparison shows [insert result here].\nThe 3:1 vs 1:1 comparison shows [insert result here].\n\nThese results provide no evidence that higher match ratios significantly increase donation rates. This aligns with the authors’ conclusion that larger match offers do not meaningfully change behavior beyond the presence of a match itself.\n\nVisualizing Donation Rates by Match Ratio\nWe now visualize the proportion of donors in each match ratio condition.\n\n\nShow code\ndata %&gt;%\n  filter(ratio == 1 | ratio2 == 1 | ratio3 == 1) %&gt;%\n  mutate(MatchRatio = case_when(\n    ratio3 == 1 ~ \"3:1\",\n    ratio2 == 1 ~ \"2:1\",\n    ratio == 1  ~ \"1:1\"\n  )) %&gt;%\n  group_by(MatchRatio) %&gt;%\n  summarise(ResponseRate = mean(gave)) %&gt;%\n  ggplot(aes(x = MatchRatio, y = ResponseRate, fill = MatchRatio)) +\n  geom_col(width = 0.6) +\n  labs(title = \"Donation Rate by Match Ratio\", y = \"Proportion Donated\", x = \"Match Ratio\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nDonation Rate by Match Ratio (1:1, 2:1, 3:1)\n\n\n\n\n\n\nRegression: Match Ratio Effects Within Treatment Group\nTo confirm the findings statistically, we regress donation probability on dummy variables for each match ratio. This regression is limited to the treatment group, where match ratio variation was introduced.\n\n\nShow code\n# Create dummies and filter to matched treatment groups\ntreat_data &lt;- data %&gt;%\n  filter(treatment == 1, ratio %in% c(1, 2, 3)) %&gt;%\n  mutate(\n    ratio1 = ifelse(ratio == 1, 1, 0),\n    ratio2 = ifelse(ratio2 == 1, 1, 0),\n    ratio3 = ifelse(ratio3 == 1, 1, 0)\n  )\n\n# Regression (1:1 match is reference)\nmodel_match_treat &lt;- lm(gave ~ ratio2 + ratio3, data = treat_data)\nkable(tidy(model_match_treat), caption = \"Regression: Effect of Match Ratio on Donation Likelihood (Treatment Only)\")\n\n\n\nRegression: Effect of Match Ratio on Donation Likelihood (Treatment Only)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.0207491\n0.0013914\n14.912217\n0.0000000\n\n\nratio2\n0.0018843\n0.0019677\n0.957582\n0.3382805\n\n\nratio3\n0.0019843\n0.0019679\n1.008301\n0.3133172\n\n\n\n\n\nThe regression results confirm the t-test findings: neither the 2:1 nor the 3:1 match rate produced a statistically significant increase in donation rates compared to the baseline 1:1 match.\nThis suggests that increasing the match multiplier does not yield additional behavioral change — what matters most is simply offering a match.\n\n\nManual Difference Check: Data and Model Coefficients\nTo reinforce our findings, we calculate response rate differences both directly from the data and using the regression coefficients.\n\n\nShow code\n# Grouped response rates\nmatch_only &lt;- treat_data\nresponse_rates &lt;- match_only %&gt;%\n  mutate(match_ratio = case_when(\n    ratio == 1 ~ \"1:1\",\n    ratio2 == 1 ~ \"2:1\",\n    ratio3 == 1 ~ \"3:1\"\n  )) %&gt;%\n  group_by(match_ratio) %&gt;%\n  summarise(ResponseRate = mean(gave), n = n())\n\n# Manual differences\nrate_2v1 &lt;- response_rates$ResponseRate[response_rates$match_ratio == \"2:1\"] -\n            response_rates$ResponseRate[response_rates$match_ratio == \"1:1\"]\n\nrate_3v2 &lt;- response_rates$ResponseRate[response_rates$match_ratio == \"3:1\"] -\n            response_rates$ResponseRate[response_rates$match_ratio == \"2:1\"]\n\n# Coefficients from regression model\nreg_results &lt;- tidy(lm(gave ~ ratio2 + ratio3, data = match_only))\ncoef_2v1 &lt;- reg_results$estimate[reg_results$term == \"ratio2\"]\ncoef_3v2 &lt;- reg_results$estimate[reg_results$term == \"ratio3\"] - reg_results$estimate[reg_results$term == \"ratio2\"]\n\n# Output\nkable(data.frame(rate_2v1, rate_3v2, coef_2v1, coef_3v2),\n      caption = \"Match Rate Differences: Manual vs Regression-Based\")\n\n\n\nMatch Rate Differences: Manual vs Regression-Based\n\n\nrate_2v1\nrate_3v2\ncoef_2v1\ncoef_3v2\n\n\n\n\n0.0018843\n1e-04\n0.0018843\n1e-04\n\n\n\n\n\nThe table above confirms that: - The 2:1 vs 1:1 difference is small in both the data and regression. - The 3:1 vs 2:1 difference is nearly zero or even slightly negative.\nThese findings reinforce the idea that increasing match size has little to no marginal effect on giving behavior.\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\nIn this section, we examine whether the treatment affected not only the likelihood of giving, but also the amount donated. We use a t-test and a bivariate linear regression to compare average donation amounts between the treatment and control groups.\n\n\nShow code\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\n\n# T-test: compare donation amounts across full sample\nt_test_amount &lt;- t.test(amount ~ treatment, data = data, var.equal = TRUE)\nt_test_amount_result &lt;- tidy(t_test_amount)\n\n# Linear regression: amount ~ treatment\nlm_amount &lt;- lm(amount ~ treatment, data = data)\nlm_amount_result &lt;- tidy(lm_amount)\n\n# Display formatted results\nkable(t_test_amount_result, caption = \"T-Test: Donation Amount by Treatment Group\")\n\n\n\nT-Test: Donation Amount by Treatment Group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.1536055\n0.8132678\n0.9668733\n-1.860503\n0.0628203\n50081\n-0.3154265\n0.0082156\nTwo Sample t-test\ntwo.sided\n\n\n\n\n\nShow code\nkable(lm_amount_result, caption = \"Regression: Donation Amount ~ Treatment\")\n\n\n\nRegression: Donation Amount ~ Treatment\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.8132678\n0.0674184\n12.062995\n0.0000000\n\n\ntreatment\n0.1536055\n0.0825613\n1.860503\n0.0628203\n\n\n\n\n\nThe results indicate that the average donation amount was slightly higher in the treatment group, but the difference was not statistically significant.\nThis suggests that while the matched donation offer may encourage more people to donate, it does not necessarily cause them to donate more money. In other words, the treatment seems to affect whether someone donates, but not how much they donate once they do.\n\nConditional on Donation\nWe now repeat the analysis, restricting to only those individuals who actually donated (gave == 1). This isolates the effect of treatment on the amount given, conditional on the decision to donate.\n\n\nShow code\n# Filter to donors only\ndonors_only &lt;- data %&gt;% filter(gave == 1)\n\n# Conditional analysis\nt_test_donors &lt;- t.test(amount ~ treatment, data = donors_only, var.equal = TRUE)\nlm_donors &lt;- lm(amount ~ treatment, data = donors_only)\n\n# Tidy and display\nkable(tidy(t_test_donors), caption = \"T-Test: Donation Amounts Among Donors Only\")\n\n\n\nT-Test: Donation Amounts Among Donors Only\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n1.668394\n45.54027\n43.87188\n0.5808393\n0.5614756\n1032\n-3.967986\n7.304773\nTwo Sample t-test\ntwo.sided\n\n\n\n\n\nShow code\nkable(tidy(lm_donors), caption = \"Regression: Donation Amount ~ Treatment (Donors Only)\")\n\n\n\nRegression: Donation Amount ~ Treatment (Donors Only)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n45.540269\n2.423378\n18.7920635\n0.0000000\n\n\ntreatment\n-1.668394\n2.872384\n-0.5808393\n0.5614756\n\n\n\n\n\n\nInterpretation (Donors Only)\nWhen we condition on giving, the treatment group still appears to give slightly more, but again, the difference is not statistically significant.\n\n\nCausality Caveat\nImportantly, this analysis is not causal. Since the treatment may have influenced who chose to give, the group of donors in each condition is not randomly assigned. As a result, differences in donation amount may be driven by selection bias, not the treatment itself.\nThis analysis helps us understand patterns in donor behavior, but does not permit a causal claim about the impact of treatment on donation size.\n\n\n\n\n\n\n\n\n\n\n\nConditional on Donation: Effect of Treatment on Donation Amount\n\n\n\n\n\nIn this section, we restrict our analysis to only those individuals who actually made a donation (gave == 1). We then compare the distribution and average size of donations between the treatment and control groups.\nThis helps answer the question: Among donors, does receiving a matched appeal influence how much people give?\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Filter donors\ndonors &lt;- data %&gt;% filter(gave == 1)\n\n# Split by group\ndonors_treat &lt;- donors %&gt;% filter(treatment == 1)\ndonors_control &lt;- donors %&gt;% filter(treatment == 0)\n\n# Plot for treatment group\np_treat &lt;- ggplot(donors_treat, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"#5DA5DA\", color = \"white\") +\n  geom_vline(xintercept = mean(donors_treat$amount), color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Treatment Group\", x = \"Donation Amount ($)\", y = \"Number of Donors\") +\n  theme_minimal()\n\n# Plot for control group\np_control &lt;- ggplot(donors_control, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"#FAA43A\", color = \"white\") +\n  geom_vline(xintercept = mean(donors_control$amount), color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Control Group\", x = \"Donation Amount ($)\", y = \"Number of Donors\") +\n  theme_minimal()\n\n# Display side-by-side\np_control + p_treat\n\n\n\n\n\nDonation Amounts Among Donors: Treatment vs. Control Groups\n\n\n\n\nEach histogram above shows the distribution of donation amounts for individuals who gave, separated by treatment status. The red dashed line represents the average donation within each group.\n\nResults:\n\nBoth groups show a right-skewed distribution, typical of donation data.\nThe treatment group’s average donation appears slightly higher, but the shapes of the distributions are quite similar.\n\n\n\nInterpretation:\nWhile the treatment group may give slightly more on average, this analysis does not imply causality. Since we’re conditioning on giving behavior (which itself may be influenced by the treatment), any differences in donation amount could be due to selection bias among those who chose to donate.\nThis section offers insight into the intensity of giving among participants but does not allow for a causal interpretation of the treatment effect on donation size.\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\n\n\n\n\n\nAs a reminder of how the t-statistic and sampling averages behave under repeated trials, this section uses simulation to demonstrate two fundamental statistical principles: the Law of Large Numbers and the Central Limit Theorem.\nSuppose that the true donation probability is: - 1.8% (p = 0.018) for individuals who do not receive a matched donation offer, and - 2.2% (p = 0.022) for individuals who do receive a matched donation offer.\nWe now simulate repeated draws from these two distributions to see whether the average difference in giving behavior converges toward the true difference.\n\n\nShow code\nset.seed(123)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Simulate 100,000 draws from control (Bernoulli with p = 0.018)\ncontrol_draws &lt;- rbinom(100000, size = 1, prob = 0.018)\n\n# Simulate 10,000 draws from treatment (Bernoulli with p = 0.022)\ntreatment_draws &lt;- rbinom(10000, size = 1, prob = 0.022)\n\n# Compute 10,000 differences between paired draws\ndifferences &lt;- treatment_draws - control_draws[1:10000]\n\n# Compute cumulative average\ncumulative_avg &lt;- cumsum(differences) / seq_along(differences)\n\n# True difference\ntrue_diff &lt;- 0.022 - 0.018\n\n# Set symmetrical y-axis limits around 0\nylim_range &lt;- max(abs(c(min(cumulative_avg), max(cumulative_avg))))\ny_limits &lt;- c(-ylim_range, ylim_range)\n\n# Plot the cumulative average\nggplot(data.frame(draw = 1:10000, cumulative_avg = cumulative_avg),\n       aes(x = draw, y = cumulative_avg)) +\n  geom_line(color = \"#3A87B9\", size = 1) +\n  geom_hline(yintercept = 0, color = \"gray50\", linetype = \"solid\") +\n  geom_hline(yintercept = true_diff, color = \"#D73027\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Cumulative Average of Simulated Differences in Donation Amounts\",\n    x = \"Number of Simulations\",\n    y = \"Cumulative Average Difference\"\n  ) +\n  coord_cartesian(ylim = y_limits) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title = element_text(face = \"bold\"),\n    axis.text = element_text(color = \"gray20\")\n  )\n\n\n\n\n\nCumulative Average of Simulated Differences in Donation Amounts\n\n\n\n\n\nInterpretation\nThe chart above shows how the cumulative average of 10,000 simulated differences in donation rates behaves as more samples are drawn. Each point on the line represents the running average of the difference between simulated treatment and control donations.\n\nThe red dashed line represents the true difference in giving probability: 0.004 (i.e., 2.2% - 1.8%).\nThe gray solid line at zero shows the null effect (no difference).\n\nAs the number of draws increases, the cumulative average quickly converges toward the true difference, demonstrating the Law of Large Numbers: with enough repeated trials, the sample mean converges to the population mean.\nThis simulation offers intuitive insight into why larger samples lead to more reliable estimates — a foundation of modern statistical inference.\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\nThis section demonstrates the Central Limit Theorem through simulation. We repeatedly sample from the treatment and control groups and calculate the difference in average donation amounts across four different sample sizes: 50, 200, 500, and 1000.\nFor each sample size: - We simulate 1,000 experiments. - In each, we draw n random observations from both the treatment and control groups (donors only). - We calculate the difference in means and record it. - We then plot the histogram of those 1,000 differences.\nThese histograms allow us to visualize how the sampling distribution changes as sample size increases.\n\n\nShow code\nset.seed(123)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Filter to donors only\ndonors &lt;- data %&gt;% filter(gave == 1)\n\n# Extract treatment and control donations\ncontrol &lt;- donors %&gt;% filter(treatment == 0) %&gt;% pull(amount)\ntreatment &lt;- donors %&gt;% filter(treatment == 1) %&gt;% pull(amount)\n\n# Calculate true mean difference\ntrue_diff &lt;- mean(treatment) - mean(control)\n\n# Simulation function\nsimulate_differences &lt;- function(n, reps = 1000) {\n  replicate(reps, {\n    mean(sample(treatment, n, replace = TRUE)) -\n      mean(sample(control, n, replace = TRUE))\n  })\n}\n\n# Simulations\ndiffs_50 &lt;- simulate_differences(50)\ndiffs_200 &lt;- simulate_differences(200)\ndiffs_500 &lt;- simulate_differences(500)\ndiffs_1000 &lt;- simulate_differences(1000)\n\n# Prettier histogram plot function\nplot_histogram &lt;- function(diffs, n, binwidth = 1.5) {\n  ggplot(data.frame(diff = diffs), aes(x = diff)) +\n    geom_histogram(aes(y = ..density.., fill = ..x..), binwidth = binwidth, color = \"white\") +\n    scale_fill_gradient(low = \"#B3DDF2\", high = \"#3A87B9\") +  # soft blue gradient\n    geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n    geom_vline(xintercept = true_diff, color = \"darkgreen\", linetype = \"dotted\", linewidth = 1) +\n    labs(\n      title = paste(\"Sample Size:\", n),\n      x = \"Difference in Mean\\nDonations (Treatment - Control)\",\n      y = \"Density\"\n    ) +\n    xlim(-10, 10) +\n    theme_minimal(base_size = 12) +\n    theme(\n      plot.title = element_text(size = 14, face = \"bold\"),\n      axis.title = element_text(face = \"bold\", size = 11),\n      axis.text = element_text(size = 9, color = \"gray20\"),\n      legend.position = \"none\"\n    )\n}\n\n# Generate 4 prettier plots\np50 &lt;- plot_histogram(diffs_50, 50)\np200 &lt;- plot_histogram(diffs_200, 200)\np500 &lt;- plot_histogram(diffs_500, 500)\np1000 &lt;- plot_histogram(diffs_1000, 1000)\n\n# Combine into 2x2 layout\n(p50 | p200) / (p500 | p1000)\n\n\n\n\n\nSampling Distribution of Mean Differences Across Sample Sizes\n\n\n\n\nThe plots above illustrate how the sampling distribution of the mean difference becomes increasingly concentrated as the sample size increases.\n\nFor n = 50, the distribution is wide and noisy — zero lies comfortably within the range of common outcomes.\nAs sample size grows, the distribution narrows.\nBy n = 1000, the distribution is tightly centered around the true treatment effect (green dotted line), and zero (red dashed line) is clearly in the tail.\n\nThis pattern is a visual demonstration of the Central Limit Theorem: as sample size increases, the distribution of sample means approaches a normal distribution centered at the true mean. It also shows why larger sample sizes improve statistical power in experiments like this one."
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt;\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt;\n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "blog/project 5/hw3_questions.html",
    "href": "blog/project 5/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "blog/project 5/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "blog/project 5/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "blog/project 5/hw3_questions.html#simulate-conjoint-data",
    "href": "blog/project 5/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n# set seed for reproducibility\nset.seed(123)\n\n# define attributes\nbrand &lt;- c(\"N\", \"P\", \"H\") # Netflix, Prime, Hulu\nad &lt;- c(\"Yes\", \"No\")\nprice &lt;- seq(8, 32, by=4)\n\n# generate all possible profiles\nprofiles &lt;- expand.grid(\n    brand = brand,\n    ad = ad,\n    price = price\n)\nm &lt;- nrow(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util &lt;- c(N = 1.0, P = 0.5, H = 0)\na_util &lt;- c(Yes = -0.8, No = 0.0)\np_util &lt;- function(p) -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps &lt;- 100\nn_tasks &lt;- 10\nn_alts &lt;- 3\n\n# function to simulate one respondent’s data\nsim_one &lt;- function(id) {\n  \n    datlist &lt;- list()\n    \n    # loop over choice tasks\n    for (t in 1:n_tasks) {\n        \n        # randomly sample 3 alts (better practice would be to use a design)\n        dat &lt;- cbind(resp=id, task=t, profiles[sample(m, size=n_alts), ])\n        \n        # compute deterministic portion of utility\n        dat$v &lt;- b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price) |&gt; round(10)\n        \n        # add Gumbel noise (Type I extreme value)\n        dat$e &lt;- -log(-log(runif(n_alts)))\n        dat$u &lt;- dat$v + dat$e\n        \n        # identify chosen alternative\n        dat$choice &lt;- as.integer(dat$u == max(dat$u))\n        \n        # store task\n        datlist[[t]] &lt;- dat\n    }\n    \n    # combine all tasks for one respondent\n    do.call(rbind, datlist)\n}\n\n# simulate data for all respondents\nconjoint_data &lt;- do.call(rbind, lapply(1:n_peeps, sim_one))\n\n# remove values unobservable to the researcher\nconjoint_data &lt;- conjoint_data[ , c(\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\")]\n\n# clean up\nrm(list=setdiff(ls(), \"conjoint_data\"))"
  },
  {
    "objectID": "blog/project 5/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "blog/project 5/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\nIn order to estimate the Multinomial Logit (MNL) model, we must restructure the conjoint data such that each row represents a single product alternative in a respondent’s choice task, along with the features of that alternative. This also requires converting the categorical variables (brand and ad) into binary indicators. We use netflix and prime as dummy variables for brand (with Hulu as the base/reference category), and an ads dummy indicating whether the offer includes advertisements (with ad-free as the reference). These variables will be the explanatory features in our utility function.\n\n\nShow code\nlibrary(dplyr)\nlibrary(knitr)\n\n# Convert brand and ad into dummy variables\ndata_mnl &lt;- conjoint_data %&gt;%\n  mutate(\n    netflix = ifelse(brand == \"N\", 1, 0),\n    prime   = ifelse(brand == \"P\", 1, 0),\n    ads     = ifelse(ad == \"Yes\", 1, 0)\n  ) %&gt;%\n  select(resp, task, price, netflix, prime, ads, choice)\n\n# Display a formatted preview table\nkable(head(data_mnl), caption = \"Preview of Prepared Data for MNL Estimation\")\n\n\n\nPreview of Prepared Data for MNL Estimation\n\n\n\nresp\ntask\nprice\nnetflix\nprime\nads\nchoice\n\n\n\n\n31\n1\n1\n28\n1\n0\n1\n1\n\n\n15\n1\n1\n16\n0\n0\n1\n0\n\n\n14\n1\n1\n16\n0\n1\n1\n0\n\n\n37\n1\n2\n32\n1\n0\n1\n0\n\n\n141\n1\n2\n16\n0\n1\n1\n1\n\n\n25\n1\n2\n24\n1\n0\n1\n0\n\n\n\nReshape and prepare data for MNL estimation\n\n\nThis prepared dataset now includes all the variables required for model estimation. The choice variable indicates whether a product was selected in a task (1) or not (0). In the next section, we will use this data to define a log-likelihood function and estimate parameters using Maximum Likelihood."
  },
  {
    "objectID": "blog/project 5/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "blog/project 5/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\nTo estimate the parameters of the Multinomial Logit (MNL) model, we define a log-likelihood function that reflects the probability of choosing each alternative. The model assumes that utility is a linear function of product attributes (e.g., brand, ads, price), and that choices are made with some unobserved randomness, modeled as a Type I extreme value error.\nWe use the optim() function in R with the BFGS optimization method to maximize the log-likelihood and obtain the parameter estimates. The Hessian matrix returned by optim() allows us to compute standard errors and 95% confidence intervals.\n\n\nShow code\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(tibble)\n\n# Prepare inputs\nX &lt;- as.matrix(data_mnl[, c(\"netflix\", \"prime\", \"ads\", \"price\")])\ny &lt;- data_mnl$choice\ngroups &lt;- interaction(data_mnl$resp, data_mnl$task)\n\n# Define the negative log-likelihood function\nmnl_loglik &lt;- function(beta) {\n  xb &lt;- X %*% beta\n  exp_xb &lt;- exp(xb)\n  denom &lt;- tapply(exp_xb, groups, sum)\n  probs &lt;- exp_xb / rep(denom, each = 3)\n  -sum(log(probs[y == 1]))\n}\n\n# Run optimization\ninit &lt;- rep(0, 4)  # initial guess for parameters\nfit &lt;- optim(init, mnl_loglik, hessian = TRUE, method = \"BFGS\")\n\n# Extract parameter estimates and standard errors\ncoef &lt;- fit$par\nse &lt;- sqrt(diag(solve(fit$hessian)))\nci_lower &lt;- coef - 1.96 * se\nci_upper &lt;- coef + 1.96 * se\n\n# Format results\nmle_results &lt;- tibble(\n  Parameter = c(\"Beta_Netflix\", \"Beta_Prime\", \"Beta_Ads\", \"Beta_Price\"),\n  Estimate = round(coef, 3),\n  Std_Error = round(se, 3),\n  CI_Lower = round(ci_lower, 3),\n  CI_Upper = round(ci_upper, 3)\n)\n\n# Show formatted table\nkable(mle_results, caption = \"Maximum Likelihood Estimates with 95% Confidence Intervals\")\n\n\n\nMaximum Likelihood Estimates with 95% Confidence Intervals\n\n\nParameter\nEstimate\nStd_Error\nCI_Lower\nCI_Upper\n\n\n\n\nBeta_Netflix\n0.941\n0.111\n0.724\n1.159\n\n\nBeta_Prime\n0.502\n0.111\n0.284\n0.719\n\n\nBeta_Ads\n-0.732\n0.088\n-0.904\n-0.560\n\n\nBeta_Price\n-0.099\n0.006\n-0.112\n-0.087\n\n\n\nMLE of MNL Model with 95% Confidence Intervals\n\n\nThe table above presents the estimated coefficients of the MNL model. All signs and magnitudes are consistent with our expectations from economic theory and the data-generating process:\n\nBeta_Netflix and Beta_Prime are positive, indicating greater preference compared to Hulu (the omitted base category).\nBeta_Ads is negative, showing that offers with advertisements are less attractive.\nBeta_Price is negative, confirming that higher prices reduce the utility of an offer.\n\nThe standard errors are relatively small, and the 95% confidence intervals do not cross zero for most parameters, suggesting statistical significance."
  },
  {
    "objectID": "blog/project 5/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "blog/project 5/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\n\n\nShow code\nset.seed(42)\n\n# Log-prior function\nlog_prior &lt;- function(beta) {\n    # N(0,5) for first 3, N(0,1) for price\n    sum(dnorm(beta[1:3], 0, 5, log=TRUE)) + dnorm(beta[4], 0, 1, log=TRUE)\n}\n\n# Log-posterior function\nlog_posterior &lt;- function(beta) {\n    -mnl_loglik(beta) + log_prior(beta)\n}\n\n# Proposal standard deviations\nprop_sd &lt;- c(0.05, 0.05, 0.05, 0.005)\n\n# MCMC settings\nn_iter &lt;- 11000\nn_params &lt;- 4\nbeta_chain &lt;- matrix(NA, nrow=n_iter, ncol=n_params)\ncolnames(beta_chain) &lt;- c(\"netflix\", \"prime\", \"ads\", \"price\")\nbeta_chain[1, ] &lt;- rep(0, n_params) # start at 0\n\naccept &lt;- 0\n\nfor (i in 2:n_iter) {\n    # Propose new beta\n    beta_prop &lt;- beta_chain[i-1, ] + rnorm(n_params, 0, prop_sd)\n    # Compute log-posterior\n    logp_curr &lt;- log_posterior(beta_chain[i-1, ])\n    logp_prop &lt;- log_posterior(beta_prop)\n    # Acceptance probability\n    log_alpha &lt;- logp_prop - logp_curr\n    if (log(runif(1)) &lt; log_alpha) {\n        beta_chain[i, ] &lt;- beta_prop\n        accept &lt;- accept + 1\n    } else {\n        beta_chain[i, ] &lt;- beta_chain[i-1, ]\n    }\n}\n\ncat(\"Acceptance rate:\", round(accept/(n_iter-1), 3), \"\\n\")\n\n\nAcceptance rate: 0.569 \n\n\nShow code\n# Discard burn-in\nburn &lt;- 1000\npost_chain &lt;- beta_chain[(burn+1):n_iter, ]\n\n# Trace plot and posterior for Beta_Netflix\npar(mfrow=c(1,2))\nplot(post_chain[,1], type=\"l\", main=\"Trace: Beta_Netflix\", ylab=\"Beta_Netflix\", xlab=\"Iteration\")\nhist(post_chain[,1], breaks=40, main=\"Posterior: Beta_Netflix\", xlab=\"Beta_Netflix\", col=\"lightblue\")\n\n\n\n\n\nMetropolis-Hastings MCMC Trace and Posterior for Beta_Netflix\n\n\n\n\nShow code\n# Posterior summaries\npost_summary &lt;- function(x) {\n    c(mean=mean(x), sd=sd(x), \n        lower=quantile(x, 0.025), \n        upper=quantile(x, 0.975))\n}\npost_stats &lt;- apply(post_chain, 2, post_summary)\npost_stats &lt;- t(round(post_stats, 3))\ncolnames(post_stats) &lt;- c(\"Mean\", \"SD\", \"2.5%\", \"97.5%\")\nknitr::kable(post_stats, caption=\"Posterior Means, SDs, and 95% Credible Intervals (MCMC)\")\n\n\n\nPosterior Means, SDs, and 95% Credible Intervals (MCMC)\n\n\n\nMean\nSD\n2.5%\n97.5%\n\n\n\n\nnetflix\n0.947\n0.114\n0.731\n1.166\n\n\nprime\n0.497\n0.116\n0.276\n0.732\n\n\nads\n-0.737\n0.088\n-0.902\n-0.564\n\n\nprice\n-0.100\n0.006\n-0.112\n-0.088\n\n\n\nMetropolis-Hastings MCMC Trace and Posterior for Beta_Netflix\n\n\nInterpretation of Bayesian Estimation Results\nThe Metropolis-Hastings MCMC algorithm was used to estimate the posterior distributions of the four model parameters: Beta_Netflix, Beta_Prime, Beta_Ads, and Beta_Price. The trace plot for Beta_Netflix shows good mixing and no obvious trends, suggesting the Markov chain has converged. The histogram displays the posterior distribution, which appears approximately normal.\nThe posterior summary table reports the mean, standard deviation, and 95% credible intervals for each parameter. These values represent our updated beliefs about the parameters after observing the data and incorporating the specified priors (N(0,5) for binary variables, N(0,1) for price).\nCompared to the Maximum Likelihood Estimates (MLE), the posterior means are similar, but the Bayesian approach provides additional uncertainty quantification via credible intervals. This reflects both the information from the data and the prior assumptions. The relatively narrow credible intervals for most parameters indicate the data is informative, while the prior has a modest regularizing effect.\n\n# Trace plot and posterior histogram for Beta_Netflix (first parameter)\npar(mfrow = c(1, 2))\nplot(post_chain[, 1], type = \"l\", main = \"Trace Plot: Beta_Netflix\",\n    xlab = \"Iteration\", ylab = \"Beta_Netflix\")\nhist(post_chain[, 1], breaks = 40, main = \"Posterior: Beta_Netflix\",\n    xlab = \"Beta_Netflix\", col = \"skyblue\")\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\n# Combine MLE and Bayesian posterior summaries for comparison\n\n# MLE results (already computed above)\nmle_table &lt;- mle_results %&gt;%\n    select(Parameter, Estimate, Std_Error, CI_Lower, CI_Upper) %&gt;%\n    rename(\n        MLE_Estimate = Estimate,\n        MLE_SD = Std_Error,\n        MLE_2.5 = CI_Lower,\n        MLE_97.5 = CI_Upper\n    )\n\n# Bayesian posterior summaries (already computed as post_stats)\nbayes_table &lt;- as_tibble(post_stats, rownames = \"Parameter\") %&gt;%\n    mutate(Parameter = c(\"Beta_Netflix\", \"Beta_Prime\", \"Beta_Ads\", \"Beta_Price\")) %&gt;%\n    rename(\n        Bayes_Mean = Mean,\n        Bayes_SD = SD,\n        Bayes_2.5 = `2.5%`,\n        Bayes_97.5 = `97.5%`\n    )\n\n# Merge for side-by-side comparison\ncomparison &lt;- left_join(mle_table, bayes_table, by = \"Parameter\")\n\n# Display comparison table\nkable(comparison, caption = \"Comparison of MLE and Bayesian Posterior Summaries for MNL Parameters\")\n\n\nComparison of MLE and Bayesian Posterior Summaries for MNL Parameters\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMLE_Estimate\nMLE_SD\nMLE_2.5\nMLE_97.5\nBayes_Mean\nBayes_SD\nBayes_2.5\nBayes_97.5\n\n\n\n\nBeta_Netflix\n0.941\n0.111\n0.724\n1.159\n0.947\n0.114\n0.731\n1.166\n\n\nBeta_Prime\n0.502\n0.111\n0.284\n0.719\n0.497\n0.116\n0.276\n0.732\n\n\nBeta_Ads\n-0.732\n0.088\n-0.904\n-0.560\n-0.737\n0.088\n-0.902\n-0.564\n\n\nBeta_Price\n-0.099\n0.006\n-0.112\n-0.087\n-0.100\n0.006\n-0.112\n-0.088"
  },
  {
    "objectID": "blog/project 5/hw3_questions.html#discussion",
    "href": "blog/project 5/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\nIf we had not simulated the data and were instead analyzing real-world conjoint data, the estimated coefficients from the MNL model would reflect actual consumer preferences. These estimates provide insight into:\nThe direction of each attribute’s effect on utility\nThe relative importance of different features (e.g., brand, ads, price)\nTrade-offs consumers are willing to make\n\nWhat does \\(\\beta_{Netflix} &gt; \\beta_{Prime}\\) mean? This inequality means that consumers, on average, derive more utility from Netflix than from Prime Video. suggests that, all else equal (price and ads held constant), Netflix is the more preferred brand. This tells us that the probability of choosing Netflix is higher compared to Prime, assuming equal price and ad status.\nDoes it make sense that \\(\\beta_\\text{price}\\) is negative ? Yes, it absolutely makes sense. A negative coefficient on price reflects the rational consumer behavior that: In words: As price increases, utility decreases Therefore, the probability of choosing that option declines\n\nThis is consistent with economic theory and consumer behavior — people generally prefer cheaper options, all else equal.\nAt a high level, to simulate and estimate a multi-level (random-parameter or hierarchical) multinomial logit model, you need to introduce individual-level heterogeneity in the preference parameters.\nSimulation:\n- Instead of using a single set of coefficients (betas) for all respondents, draw a unique set of coefficients for each individual from a population distribution (e.g., multivariate normal with mean vector μ and covariance Σ). - For each respondent, use their own coefficients to generate choices in the same way as before.\nEstimation:\n- The likelihood now involves integrating over the distribution of individual-level coefficients, which is not analytically tractable. - Use hierarchical Bayesian methods (e.g., Gibbs sampling, Hamiltonian Monte Carlo) or simulated maximum likelihood (e.g., using importance sampling or draws from the random coefficients) to estimate both the population-level parameters (μ, Σ) and the individual-level betas. - This approach captures preference heterogeneity and provides more realistic inference for real-world conjoint data."
  },
  {
    "objectID": "blog/project4/hw2_questions.html",
    "href": "blog/project4/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nData\n\n\n\n\n\n\n\nShow code\nlibrary(tidyverse)\n\n# Read in the Blueprinty dataset\nblueprinty &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/blueprinty.csv\")\nairbnb &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/airbnb.csv\")\n\n\n\n\n\n\n\n\n\n\n\nPatent Count Distributions by Customer Status\n\n\n\n\n\n\n\nShow code\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(iscustomer = factor(iscustomer, levels = c(0, 1), labels = c(\"Non-Customer\", \"Customer\")))\n\nhist_non &lt;- ggplot(filter(blueprinty, iscustomer == \"Non-Customer\"),\n                   aes(x = patents)) +\n  geom_histogram(binwidth = 1, fill = \"#90CAF9\", color = \"black\") +\n  labs(title = \"Non-Customers\", x = \"Patents Awarded\", y = \"Count\") +\n  theme_minimal()\n\nhist_cust &lt;- ggplot(filter(blueprinty, iscustomer == \"Customer\"),\n                    aes(x = patents)) +\n  geom_histogram(binwidth = 1, fill = \"#F48FB1\", color = \"black\") +\n  labs(title = \"Customers\", x = \"Patents Awarded\", y = \"Count\") +\n  theme_minimal()\n\nhist_non + hist_cust\n\n\n\n\n\nComparison of patents awarded between Blueprinty customers and non-customers\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(knitr)\n\nblueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    mean_patents = round(mean(patents), 2),\n    n = n()\n  ) %&gt;%\n  mutate(iscustomer = ifelse(iscustomer == 1, \"Customer\", \"Non-Customer\")) %&gt;%\n  kable(\n    caption = \"Mean number of patents awarded by Blueprinty customer status\",\n    col.names = c(\"Customer Status\", \"Mean Patents\", \"Sample Size\")\n  )\n\n\n\nMean number of patents awarded by Blueprinty customer status\n\n\nCustomer Status\nMean Patents\nSample Size\n\n\n\n\nNon-Customer\n3.47\n1019\n\n\nNon-Customer\n4.13\n481\n\n\n\n\n\nIn this analysis, we compare the distribution of patents awarded between Blueprinty customers and non-customers. The histograms show that customers tend to have higher patent counts on average. The accompanying summary table confirms this, with customers averaging 4.13 patents versus 3.47 for non-customers. This suggests a potential association between using Blueprinty’s software and increased innovation output. However, because customer status is not randomly assigned, these differences may also be influenced by other factors like firm age or region. To account for these confounding variables, we proceed with a Poisson regression model that adjusts for such covariate\nFirms that use Blueprinty’s software tend to have a distribution shifted toward higher patent counts, suggesting a possible link between software use and innovation productivity. However, because customer status is not randomly assigned, these differences could reflect other factors like firm age or region, which we will adjust for in the Poisson regression.\n\n\n\n\n\n\n\n\n\nDemographic Differences Between Blueprinty Customers and Non-Customers\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nShow code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Rename your dataset to avoid conflict with built-in function\nblueprinty &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/blueprinty.csv\")\n\n# Remove missing customer values and label them\nblueprinty &lt;- blueprinty %&gt;%\n  filter(!is.na(iscustomer)) %&gt;%\n  mutate(iscustomer = factor(iscustomer, labels = c(\"Non-Customer\", \"Customer\")))\n\n# -----------------------------\n# 1. Age Distribution Boxplot\n# -----------------------------\nggplot(blueprinty, aes(x = iscustomer, y = age, fill = iscustomer)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(\n    title = \"Age Distribution by Customer Status\",\n    x = \"Customer Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\"))\n\n\n\n\n\n\n\n\n\nShow code\n# -----------------------------\n# 2. Region Distribution Barplot\n# -----------------------------\nblueprinty %&gt;%\n  group_by(region, iscustomer) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(iscustomer) %&gt;%\n  mutate(percentage = count / sum(count) * 100) %&gt;%\n  ggplot(aes(x = region, y = percentage, fill = iscustomer)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  labs(\n    title = \"Region Distribution by Customer Status\",\n    x = \"Region\",\n    y = \"Percentage (%)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"orange\", \"tomato\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nTo investigate whether customer and non-customer firms differ demographically, we compare their age and regional distributions. The boxplot of Age Distribution by Customer Status shows that customers tend to be slightly older on average, although there is considerable overlap between the two groups. This age difference may partly explain the higher patent counts observed among customers earlier.\nWe also examine regional representation using a grouped bar chart. The plot indicates that Blueprinty customers are disproportionately concentrated in the Northeast, while non-customers are more evenly spread across other regions like the Midwest and South. These regional and age-based differences highlight the importance of controlling for such covariates when modeling patent outcomes — otherwise, we risk attributing differences in patenting activity to software use when they may actually stem from underlying demographic variation\n\n\n\n\n\n\n\n\n\nEstimation of Simple Poisson Model\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe probability mass function of the Poisson distribution is given by:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nAssuming we have ( n ) independent observations ( Y_1, Y_2, , Y_n ), the likelihood function is:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nTaking the natural logarithm of the likelihood, the log-likelihood function becomes:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nThis function will be maximized in the next step to estimate the value of ( ) that best fits the data.\n\n\n\n\n\n\n\n\n\nExploring the Poisson Likelihood Function\n\n\n\n\n\nTo estimate the parameter 𝜆 λ for a Poisson distribution, we begin by examining the shape of the log-likelihood function. The log-likelihood measures how well different values of 𝜆 λ explain the observed number of patents in our sample. The value that maximizes this function is the maximum likelihood estimate (MLE).\nBelow, we evaluate the log-likelihood across a range of plausible 𝜆 λ values and visualize the results. This approach gives us insight into how sensitive the model fit is to different assumptions about the average patent rate.\n\n\nShow code\n# Sample vector Y: observed patent counts\nY &lt;- blueprinty$patents\n\n# Define log-likelihood function for Poisson with constant lambda\nloglik_poisson &lt;- function(lambda, y) {\n  if (lambda &lt;= 0) return(-Inf)  # Poisson requires lambda &gt; 0\n  sum(dpois(y, lambda, log = TRUE))\n}\n\n# Generate a sequence of lambda values to test\nlambda_vals &lt;- seq(0.1, 10, by = 0.1)\n\n# Compute log-likelihood for each lambda\nloglik_vals &lt;- sapply(lambda_vals, loglik_poisson, y = Y)\n\n# Plot log-likelihood vs lambda\nlibrary(ggplot2)\n\nggplot(data.frame(lambda = lambda_vals, loglik = loglik_vals), aes(x = lambda, y = loglik)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_vline(xintercept = mean(Y), linetype = \"dashed\", color = \"darkred\") +\n  labs(\n    title = \"Log-Likelihood for Poisson Model\",\n    x = expression(lambda),\n    y = \"Log-Likelihood\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nLog-likelihood of the Poisson model across different lambda values\n\n\n\n\nThe plot shows that the log-likelihood peaks around 𝜆 = mean ( 𝑌 ) λ=mean(Y), which aligns with the known result that the MLE for a Poisson model with constant 𝜆 λ is simply the sample mean. This validates our understanding of how the Poisson distribution behaves and sets the stage for fitting a full model using optim() or glm() in the next step.\n\n\n\n\n\n\n\n\n\nDeriving the MLE Analytically\n\n\n\n\n\nTo deepen our understanding of the Poisson likelihood, we can derive the MLE analytically by taking the first derivative of the log-likelihood function and solving for ( ).\nRecall the log-likelihood for ( n ) independent observations ( Y_1, Y_2, , Y_n () ) is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i\n\\]\nSetting this derivative equal to 0 and solving for ( ):\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i = 0 \\quad \\Rightarrow \\quad\n\\hat{\\lambda} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\nThus, the MLE of ( ) is simply the sample mean ( {Y} ). This result makes intuitive sense: the Poisson distribution models count data with a mean equal to ( ), so it’s natural that the best estimate of ( ) is the average count in the data.\n\n\n\n\n\n\n\n\n\nMaximum Likelihood Estimation Using optim()\n\n\n\n\n\nTo estimate the value of 𝜆 λ that best explains our observed patent counts, we use Maximum Likelihood Estimation (MLE). The log-likelihood function we defined earlier is maximized using R’s optim() function. Since optim() minimizes by default, we provide the negative log-likelihood as the objective function.\n\n\nShow code\n# Define negative log-likelihood function\nneg_loglik_poisson &lt;- function(lambda, y) {\n  if (lambda &lt;= 0) return(Inf)  # invalid λ\n  -sum(dpois(y, lambda, log = TRUE))\n}\n\n# Run optimization using initial guess\nmle_result &lt;- optim(\n  par = 1,  # initial guess for lambda\n  fn = neg_loglik_poisson,\n  y = blueprinty$patents,\n  method = \"Brent\",  # 1D optimization method\n  lower = 0.01, upper = 20\n)\n\n# Print estimated lambda\nmle_result$par\n\n\n[1] 3.684667\n\n\n\n\nThe optimizer returns a maximum likelihood estimate of:\n\\[\n\\hat{\\lambda} \\approx 3.685\n\\]\nThis is very close to the sample mean of the observed number of patents. This confirms the theoretical result that, for a Poisson model with constant ( ), the MLE of ( ) is simply the sample mean:\n\\[\n\\hat{\\lambda}_{\\text{theory}} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i\n\\]\n\n\n\n\n\n\n\n\n\n\nEstimation of Poisson Regression Model\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nShow code\n# Log-likelihood for Poisson Regression Model\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  # Convert beta to vector if needed\n  beta &lt;- as.numeric(beta)\n  \n  # Linear predictor: eta = X * beta\n  eta &lt;- X %*% beta\n  \n  # Inverse link function: lambda = exp(eta)\n  lambda &lt;- exp(eta)\n\n  # Log-likelihood: sum over all observations\n  loglikelihood &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  \n  # Return NEGATIVE log-likelihood for minimization via optim()\n  return(-loglikelihood)\n}\n\n\nThe Poisson Regression model assumes:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i), \\quad \\text{where} \\quad \\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThe corresponding log-likelihood function is:\n\\[\n\\log \\mathcal{L}(\\beta) = \\sum_{i=1}^{n} \\left[ Y_i \\log(\\lambda_i) - \\lambda_i - \\log(Y_i!) \\right]\n\\]\nSubstituting ( _i = (X_i^) ), we get:\n\\[\n\\log \\mathcal{L}(\\beta) = \\sum_{i=1}^{n} \\left[ Y_i X_i^\\top \\beta - \\exp(X_i^\\top \\beta) - \\log(Y_i!) \\right]\n\\]\nExplanation of Model Setup\nThis section introduces the Poisson regression model, which is used to model count data—in this case, the number of patents awarded to firms. The model assumes that the expected count, ( _i ), is not constant across firms but instead depends on firm-specific characteristics such as age, age squared, region, and customer status. These features are captured in the design matrix ( X_i ), and their influence is modeled through the linear predictor ( X_i^).\nTo ensure that the predicted count ( _i ) is always positive (a requirement for count data), the model uses the exponential link function:\n[ _i = (X_i^) ]\nThe log-likelihood function shown here is the objective we will maximize to estimate the model parameters ( ). This function captures how likely the observed data are given a particular set of parameter values, and maximizing it gives us the most plausible coefficients under the Poisson model assumptions.\nThis setup forms the mathematical foundation for fitting the model using optimization routines like optim() in R.\n\n\n\n\n\n\n\n\n\nPoisson Regression Estimation, Validation, and Interpretation of Patent Award Drivers\n\n\n\n\n\n\n\nRun full estimation\n# Load libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# Step 1: Load and preprocess data\nblueprinty &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/blueprinty.csv\") %&gt;%\n  mutate(\n    age_sq = age^2,\n    region = factor(region),\n    customer = as.integer(iscustomer)  # Fix here: use iscustomer\n  )\n\n# Step 2: Create design matrix and response\nX &lt;- model.matrix(~ age + age_sq + region + customer, data = blueprinty)\nY &lt;- blueprinty$patents\ninit_beta &lt;- rep(0, ncol(X))  # Initial guess for optimization\n\n# Step 3: Define Poisson log-likelihood function\npoisson_regression_likelihood &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta\n  lambda &lt;- exp(eta)\n  loglik &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  return(-loglik)\n}\n\n# Step 4: Optimize\nmle_result &lt;- optim(\n  par = init_beta,\n  fn = poisson_regression_likelihood,\n  Y = Y,\n  X = X,\n  hessian = TRUE,\n  method = \"BFGS\"\n)\n\n# Step 5: Extract estimates and SEs\nbeta_hat &lt;- mle_result$par\nhessian &lt;- mle_result$hessian\n\n# Check Hessian validity\nif (!is.null(hessian) && is.matrix(hessian)) {\n  var_cov &lt;- solve(hessian)\n  se_hat &lt;- sqrt(diag(var_cov))\n} else {\n  se_hat &lt;- rep(NA, length(beta_hat))\n  warning(\"Hessian is invalid; SEs not computed.\")\n}\n\n# Step 6: Output results\nresults &lt;- tibble(\n  Term = colnames(X),\n  Estimate = round(beta_hat, 4),\n  `Std. Error` = round(se_hat, 4)\n)\n\nkable(results, caption = \"Poisson Regression Coefficient Estimates and Standard Errors\")\n\n\n\nPoisson Regression Coefficient Estimates and Standard Errors\n\n\nTerm\nEstimate\nStd. Error\n\n\n\n\n(Intercept)\n-0.1257\n0.1122\n\n\nage\n0.1158\n0.0064\n\n\nage_sq\n-0.0022\n0.0001\n\n\nregionNortheast\n-0.0246\n0.0434\n\n\nregionNorthwest\n-0.0348\n0.0529\n\n\nregionSouth\n-0.0054\n0.0524\n\n\nregionSouthwest\n-0.0378\n0.0472\n\n\ncustomer\n0.0607\n0.0321\n\n\n\n\n\n\n\nShow glm() regression results\n# Load necessary libraries\nlibrary(broom)\nlibrary(knitr)\n\n# Fit Poisson regression using glm()\nglm_model &lt;- glm(\n  patents ~ age + I(age^2) + region + customer,\n  data = blueprinty,\n  family = poisson(link = \"log\")\n)\n\n# Tidy up results and round for presentation\nglm_results &lt;- tidy(glm_model) %&gt;%\n  mutate(\n    Estimate = round(estimate, 4),\n    `Std. Error` = round(std.error, 4),\n    `z value` = round(statistic, 2),\n    `p-value` = round(p.value, 4)\n  ) %&gt;%\n  select(term, Estimate, `Std. Error`, `z value`, `p-value`)\n\n# Output as a formatted table\nkable(glm_results, caption = \"Poisson Regression Results Using glm()\")\n\n\n\nPoisson Regression Results Using glm()\n\n\nterm\nEstimate\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n-0.5089\n0.1832\n-2.78\n0.0055\n\n\nage\n0.1486\n0.0139\n10.72\n0.0000\n\n\nI(age^2)\n-0.0030\n0.0003\n-11.51\n0.0000\n\n\nregionNortheast\n0.0292\n0.0436\n0.67\n0.5037\n\n\nregionNorthwest\n-0.0176\n0.0538\n-0.33\n0.7438\n\n\nregionSouth\n0.0566\n0.0527\n1.07\n0.2828\n\n\nregionSouthwest\n0.0506\n0.0472\n1.07\n0.2839\n\n\ncustomer\n0.2076\n0.0309\n6.72\n0.0000\n\n\n\n\n\n\n\nThe Poisson regression estimates the expected number of patents awarded as a function of firm age, region, and whether the firm is a Blueprinty customer.\n\n\n\nCustomer (Estimate = 0.2076, p &lt; 0.001)\nBeing a Blueprinty customer is associated with a significantly higher rate of patent awards.\nInterpreting the coefficient:\n\\[\\exp(0.2076) \\approx 1.23\\]\nCustomers have about 23% more patents, on average, than non-customers, holding other factors constant.\nAge and Age² (Both p &lt; 0.001)\nThe relationship between firm age and patent success is non-linear:\n\nThe positive coefficient on age suggests older firms initially file more patents.\n\nThe negative coefficient on age² implies diminishing returns with age — a concave-down relationship.\n\nRegion Variables (All p &gt; 0.05)\nNone of the regional dummies are statistically significant. This suggests that region is not a strong predictor of patent success in this model.\nIntercept (Estimate = -0.5089, p = 0.0055)\nRepresents the log expected count of patents for a non-customer firm in the baseline region (e.g., Midwest), with age and age² = 0. Mostly useful as a baseline level.\n\n\n\n\n\n\n\n\n\n\n\n\nConclusion\n\n\n\n\n\nTo understand the practical effect of Blueprinty’s software on patent success, we compute predicted patent counts under two scenarios:\n\nX₀: Each firm is treated as a non-customer (customer = 0)\nX₁: Each firm is treated as a customer (customer = 1)\n\nUsing the estimated Poisson regression model, we compute predicted values (y_pred_0 and y_pred_1) and then take the average difference.\n\nEstimate average effect of Blueprinty’s software using counterfactuals\n# Make sure glm_result exists (run glm before this!)\nif (!exists(\"glm_result\")) {\n  glm_result &lt;- glm(\n    patents ~ age + I(age^2) + region + iscustomer,\n    data = blueprinty,\n    family = poisson(link = \"log\")\n  )\n}\n\n# Step 1: Create counterfactual design matrices\nX_0 &lt;- model.matrix(~ age + I(age^2) + region + iscustomer,\n                    data = blueprinty %&gt;% mutate(iscustomer = 0))\nX_1 &lt;- model.matrix(~ age + I(age^2) + region + iscustomer,\n                    data = blueprinty %&gt;% mutate(iscustomer = 1))\n\n# Step 2: Predict lambda (expected number of patents)\nlambda_0 &lt;- exp(X_0 %*% coef(glm_result))\nlambda_1 &lt;- exp(X_1 %*% coef(glm_result))\n\n# Step 3: Compute average difference\naverage_effect &lt;- mean(lambda_1 - lambda_0)\n\n# Step 4: Display result\naverage_effect\n\n[1] 0.7927681\n\n\nThe analysis reveals that, on average, firms using Blueprinty’s software are predicted to receive approximately 0.79 more patents over a 5-year period compared to if they were not customers — holding all other factors (such as age and region) constant.\nThis suggests that Blueprinty’s product is associated with a substantial and positive effect on patent success. While this estimate supports the marketing team’s claims, it is important to note that the analysis is observational in nature and does not account for unmeasured confounders (e.g., firm size, innovation strategy), which could influence the result.\n\n\n\n\n\n\n\n\n\n\nAirBnB Case Study\n\n\n\n\n\n\n\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis & Cleaning\n\n\n\n\n\n\n\nLoad and explore AirBnB dataset\nlibrary(tidyverse)\nlibrary(knitr)\n\n# Load data\nairbnb &lt;- read_csv(\"airbnb.csv\")\n\n# Select relevant variables and drop rows with NAs\nairbnb_clean &lt;- airbnb %&gt;%\n  select(number_of_reviews, room_type, price, bathrooms, bedrooms,\n         review_scores_cleanliness, review_scores_location, review_scores_value,\n         instant_bookable, days) %&gt;%\n  drop_na()\n\n# Nicely formatted summary statistics for number_of_reviews\nairbnb_clean %&gt;%\n  summarise(\n    Min = min(number_of_reviews),\n    Q1 = quantile(number_of_reviews, 0.25),\n    Median = median(number_of_reviews),\n    Mean = mean(number_of_reviews),\n    Q3 = quantile(number_of_reviews, 0.75),\n    Max = max(number_of_reviews)\n  ) %&gt;%\n  kable(caption = \"Summary Statistics: Number of Reviews\")\n\n\n\nSummary Statistics: Number of Reviews\n\n\nMin\nQ1\nMedian\nMean\nQ3\nMax\n\n\n\n\n1\n3\n8\n21.17089\n26\n421\n\n\n\n\n\nLoad and explore AirBnB dataset\n# Nicely formatted table of room types\nairbnb_clean %&gt;%\n  count(room_type, name = \"Count\") %&gt;%\n  kable(caption = \"Room Type Frequency Table\")\n\n\n\nRoom Type Frequency Table\n\n\nroom_type\nCount\n\n\n\n\nEntire home/apt\n15543\n\n\nPrivate room\n13773\n\n\nShared room\n844\n\n\n\n\n\n\n\nPlot EDA graphs\n# Histogram of number_of_reviews\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(fill = \"#2c7fb8\", color = \"white\", bins = 50) +\n  labs(title = \"Distribution of Number of Reviews\",\n       x = \"Number of Reviews\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\nDistribution of Number of Reviews\n\n\n\n\n\n\nBoxplot by Room Type\n# Boxplot of reviews by room_type\nggplot(airbnb_clean, aes(x = room_type, y = number_of_reviews, fill = room_type)) +\n  geom_boxplot() +\n  labs(title = \"Number of Reviews by Room Type\",\n       x = \"Room Type\", y = \"Number of Reviews\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nNumber of Reviews by Room Type\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Model\n\n\n\n\n\n\n\nFit and display Poisson regression results\nlibrary(broom)\nlibrary(knitr)\n\n# Fit Poisson regression model\npoisson_model &lt;- glm(\n  number_of_reviews ~ room_type + price + bathrooms + bedrooms + \n    review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable + days,\n  data = airbnb_clean,\n  family = poisson(link = \"log\")\n)\n\n# Tidy the summary and format\ntidy(poisson_model) %&gt;%\n  mutate(\n    Estimate = round(estimate, 4),\n    `Std. Error` = round(std.error, 4),\n    `z value` = round(statistic, 2),\n    `p-value` = round(p.value, 4)\n  ) %&gt;%\n  select(term, Estimate, `Std. Error`, `z value`, `p-value`) %&gt;%\n  kable(caption = \"Poisson Regression Results: Number of Reviews\")\n\n\n\nPoisson Regression Results: Number of Reviews\n\n\nterm\nEstimate\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n3.4980\n0.0161\n217.40\n0.0000\n\n\nroom_typePrivate room\n-0.0105\n0.0027\n-3.85\n0.0001\n\n\nroom_typeShared room\n-0.2463\n0.0086\n-28.58\n0.0000\n\n\nprice\n0.0000\n0.0000\n-2.15\n0.0315\n\n\nbathrooms\n-0.1177\n0.0037\n-31.39\n0.0000\n\n\nbedrooms\n0.0741\n0.0020\n37.20\n0.0000\n\n\nreview_scores_cleanliness\n0.1131\n0.0015\n75.61\n0.0000\n\n\nreview_scores_location\n-0.0769\n0.0016\n-47.80\n0.0000\n\n\nreview_scores_value\n-0.0911\n0.0018\n-50.49\n0.0000\n\n\ninstant_bookableTRUE\n0.3459\n0.0029\n119.67\n0.0000\n\n\ndays\n0.0001\n0.0000\n129.76\n0.0000\n\n\n\n\n\n\n\n\n\n\n\nThe model reveals significant variation in review counts based on listing characteristics:\n\nRoom Type: Compared to an entire home, private and shared rooms tend to have different review patterns. Coefficients can be exponentiated to interpret as multiplicative changes.\nPrice: A higher price is associated with a lower number of reviews, likely reflecting reduced affordability.\nReview Scores: Cleanliness, location, and value ratings are positively associated with bookings — cleaner, well-located, and good-value properties tend to get more reviews.\nInstant Bookable: Listings marked as instantly bookable receive more reviews on average.\nDays Listed: The longer a property has been on the platform, the more reviews it accumulates — as expected.\n\nOverall, the Poisson model helps quantify how various features influence demand (proxied by review counts) on Airbnb."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nData\n\n\n\n\n\n\n\nShow code\nlibrary(tidyverse)\n\n# Read in the Blueprinty dataset\nblueprinty &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/blueprinty.csv\")\nairbnb &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/airbnb.csv\")\n\n\n\n\n\n\n\n\n\n\n\nPatent Count Distributions by Customer Status\n\n\n\n\n\n\n\nShow code\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\nblueprinty &lt;- blueprinty %&gt;%\n  mutate(iscustomer = factor(iscustomer, levels = c(0, 1), labels = c(\"Non-Customer\", \"Customer\")))\n\nhist_non &lt;- ggplot(filter(blueprinty, iscustomer == \"Non-Customer\"),\n                   aes(x = patents)) +\n  geom_histogram(binwidth = 1, fill = \"#90CAF9\", color = \"black\") +\n  labs(title = \"Non-Customers\", x = \"Patents Awarded\", y = \"Count\") +\n  theme_minimal()\n\nhist_cust &lt;- ggplot(filter(blueprinty, iscustomer == \"Customer\"),\n                    aes(x = patents)) +\n  geom_histogram(binwidth = 1, fill = \"#F48FB1\", color = \"black\") +\n  labs(title = \"Customers\", x = \"Patents Awarded\", y = \"Count\") +\n  theme_minimal()\n\nhist_non + hist_cust\n\n\n\n\n\nComparison of patents awarded between Blueprinty customers and non-customers\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(knitr)\n\nblueprinty %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(\n    mean_patents = round(mean(patents), 2),\n    n = n()\n  ) %&gt;%\n  mutate(iscustomer = ifelse(iscustomer == 1, \"Customer\", \"Non-Customer\")) %&gt;%\n  kable(\n    caption = \"Mean number of patents awarded by Blueprinty customer status\",\n    col.names = c(\"Customer Status\", \"Mean Patents\", \"Sample Size\")\n  )\n\n\n\nMean number of patents awarded by Blueprinty customer status\n\n\nCustomer Status\nMean Patents\nSample Size\n\n\n\n\nNon-Customer\n3.47\n1019\n\n\nNon-Customer\n4.13\n481\n\n\n\n\n\nIn this analysis, we compare the distribution of patents awarded between Blueprinty customers and non-customers. The histograms show that customers tend to have higher patent counts on average. The accompanying summary table confirms this, with customers averaging 4.13 patents versus 3.47 for non-customers. This suggests a potential association between using Blueprinty’s software and increased innovation output. However, because customer status is not randomly assigned, these differences may also be influenced by other factors like firm age or region. To account for these confounding variables, we proceed with a Poisson regression model that adjusts for such covariate\nFirms that use Blueprinty’s software tend to have a distribution shifted toward higher patent counts, suggesting a possible link between software use and innovation productivity. However, because customer status is not randomly assigned, these differences could reflect other factors like firm age or region, which we will adjust for in the Poisson regression.\n\n\n\n\n\n\n\n\n\nDemographic Differences Between Blueprinty Customers and Non-Customers\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nShow code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Rename your dataset to avoid conflict with built-in function\nblueprinty &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/blueprinty.csv\")\n\n# Remove missing customer values and label them\nblueprinty &lt;- blueprinty %&gt;%\n  filter(!is.na(iscustomer)) %&gt;%\n  mutate(iscustomer = factor(iscustomer, labels = c(\"Non-Customer\", \"Customer\")))\n\n# -----------------------------\n# 1. Age Distribution Boxplot\n# -----------------------------\nggplot(blueprinty, aes(x = iscustomer, y = age, fill = iscustomer)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(\n    title = \"Age Distribution by Customer Status\",\n    x = \"Customer Status\",\n    y = \"Age\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\"))\n\n\n\n\n\n\n\n\n\nShow code\n# -----------------------------\n# 2. Region Distribution Barplot\n# -----------------------------\nblueprinty %&gt;%\n  group_by(region, iscustomer) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(iscustomer) %&gt;%\n  mutate(percentage = count / sum(count) * 100) %&gt;%\n  ggplot(aes(x = region, y = percentage, fill = iscustomer)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  labs(\n    title = \"Region Distribution by Customer Status\",\n    x = \"Region\",\n    y = \"Percentage (%)\",\n    fill = \"Customer Status\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"orange\", \"tomato\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nTo investigate whether customer and non-customer firms differ demographically, we compare their age and regional distributions. The boxplot of Age Distribution by Customer Status shows that customers tend to be slightly older on average, although there is considerable overlap between the two groups. This age difference may partly explain the higher patent counts observed among customers earlier.\nWe also examine regional representation using a grouped bar chart. The plot indicates that Blueprinty customers are disproportionately concentrated in the Northeast, while non-customers are more evenly spread across other regions like the Midwest and South. These regional and age-based differences highlight the importance of controlling for such covariates when modeling patent outcomes — otherwise, we risk attributing differences in patenting activity to software use when they may actually stem from underlying demographic variation\n\n\n\n\n\n\n\n\n\nEstimation of Simple Poisson Model\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe probability mass function of the Poisson distribution is given by:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nAssuming we have ( n ) independent observations ( Y_1, Y_2, , Y_n ), the likelihood function is:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nTaking the natural logarithm of the likelihood, the log-likelihood function becomes:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nThis function will be maximized in the next step to estimate the value of ( ) that best fits the data.\n\n\n\n\n\n\n\n\n\nExploring the Poisson Likelihood Function\n\n\n\n\n\nTo estimate the parameter 𝜆 λ for a Poisson distribution, we begin by examining the shape of the log-likelihood function. The log-likelihood measures how well different values of 𝜆 λ explain the observed number of patents in our sample. The value that maximizes this function is the maximum likelihood estimate (MLE).\nBelow, we evaluate the log-likelihood across a range of plausible 𝜆 λ values and visualize the results. This approach gives us insight into how sensitive the model fit is to different assumptions about the average patent rate.\n\n\nShow code\n# Sample vector Y: observed patent counts\nY &lt;- blueprinty$patents\n\n# Define log-likelihood function for Poisson with constant lambda\nloglik_poisson &lt;- function(lambda, y) {\n  if (lambda &lt;= 0) return(-Inf)  # Poisson requires lambda &gt; 0\n  sum(dpois(y, lambda, log = TRUE))\n}\n\n# Generate a sequence of lambda values to test\nlambda_vals &lt;- seq(0.1, 10, by = 0.1)\n\n# Compute log-likelihood for each lambda\nloglik_vals &lt;- sapply(lambda_vals, loglik_poisson, y = Y)\n\n# Plot log-likelihood vs lambda\nlibrary(ggplot2)\n\nggplot(data.frame(lambda = lambda_vals, loglik = loglik_vals), aes(x = lambda, y = loglik)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_vline(xintercept = mean(Y), linetype = \"dashed\", color = \"darkred\") +\n  labs(\n    title = \"Log-Likelihood for Poisson Model\",\n    x = expression(lambda),\n    y = \"Log-Likelihood\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nLog-likelihood of the Poisson model across different lambda values\n\n\n\n\nThe plot shows that the log-likelihood peaks around 𝜆 = mean ( 𝑌 ) λ=mean(Y), which aligns with the known result that the MLE for a Poisson model with constant 𝜆 λ is simply the sample mean. This validates our understanding of how the Poisson distribution behaves and sets the stage for fitting a full model using optim() or glm() in the next step.\n\n\n\n\n\n\n\n\n\nDeriving the MLE Analytically\n\n\n\n\n\nTo deepen our understanding of the Poisson likelihood, we can derive the MLE analytically by taking the first derivative of the log-likelihood function and solving for ( ).\nRecall the log-likelihood for ( n ) independent observations ( Y_1, Y_2, , Y_n () ) is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i\n\\]\nSetting this derivative equal to 0 and solving for ( ):\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i = 0 \\quad \\Rightarrow \\quad\n\\hat{\\lambda} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\nThus, the MLE of ( ) is simply the sample mean ( {Y} ). This result makes intuitive sense: the Poisson distribution models count data with a mean equal to ( ), so it’s natural that the best estimate of ( ) is the average count in the data.\n\n\n\n\n\n\n\n\n\nMaximum Likelihood Estimation Using optim()\n\n\n\n\n\nTo estimate the value of 𝜆 λ that best explains our observed patent counts, we use Maximum Likelihood Estimation (MLE). The log-likelihood function we defined earlier is maximized using R’s optim() function. Since optim() minimizes by default, we provide the negative log-likelihood as the objective function.\n\n\nShow code\n# Define negative log-likelihood function\nneg_loglik_poisson &lt;- function(lambda, y) {\n  if (lambda &lt;= 0) return(Inf)  # invalid λ\n  -sum(dpois(y, lambda, log = TRUE))\n}\n\n# Run optimization using initial guess\nmle_result &lt;- optim(\n  par = 1,  # initial guess for lambda\n  fn = neg_loglik_poisson,\n  y = blueprinty$patents,\n  method = \"Brent\",  # 1D optimization method\n  lower = 0.01, upper = 20\n)\n\n# Print estimated lambda\nmle_result$par\n\n\n[1] 3.684667\n\n\n\n\nThe optimizer returns a maximum likelihood estimate of:\n\\[\n\\hat{\\lambda} \\approx 3.685\n\\]\nThis is very close to the sample mean of the observed number of patents. This confirms the theoretical result that, for a Poisson model with constant ( ), the MLE of ( ) is simply the sample mean:\n\\[\n\\hat{\\lambda}_{\\text{theory}} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i\n\\]\n\n\n\n\n\n\n\n\n\n\nEstimation of Poisson Regression Model\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nShow code\n# Log-likelihood for Poisson Regression Model\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  # Convert beta to vector if needed\n  beta &lt;- as.numeric(beta)\n  \n  # Linear predictor: eta = X * beta\n  eta &lt;- X %*% beta\n  \n  # Inverse link function: lambda = exp(eta)\n  lambda &lt;- exp(eta)\n\n  # Log-likelihood: sum over all observations\n  loglikelihood &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  \n  # Return NEGATIVE log-likelihood for minimization via optim()\n  return(-loglikelihood)\n}\n\n\nThe Poisson Regression model assumes:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i), \\quad \\text{where} \\quad \\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThe corresponding log-likelihood function is:\n\\[\n\\log \\mathcal{L}(\\beta) = \\sum_{i=1}^{n} \\left[ Y_i \\log(\\lambda_i) - \\lambda_i - \\log(Y_i!) \\right]\n\\]\nSubstituting ( _i = (X_i^) ), we get:\n\\[\n\\log \\mathcal{L}(\\beta) = \\sum_{i=1}^{n} \\left[ Y_i X_i^\\top \\beta - \\exp(X_i^\\top \\beta) - \\log(Y_i!) \\right]\n\\]\nExplanation of Model Setup\nThis section introduces the Poisson regression model, which is used to model count data—in this case, the number of patents awarded to firms. The model assumes that the expected count, ( _i ), is not constant across firms but instead depends on firm-specific characteristics such as age, age squared, region, and customer status. These features are captured in the design matrix ( X_i ), and their influence is modeled through the linear predictor ( X_i^).\nTo ensure that the predicted count ( _i ) is always positive (a requirement for count data), the model uses the exponential link function:\n[ _i = (X_i^) ]\nThe log-likelihood function shown here is the objective we will maximize to estimate the model parameters ( ). This function captures how likely the observed data are given a particular set of parameter values, and maximizing it gives us the most plausible coefficients under the Poisson model assumptions.\nThis setup forms the mathematical foundation for fitting the model using optimization routines like optim() in R.\n\n\n\n\n\n\n\n\n\nPoisson Regression Estimation, Validation, and Interpretation of Patent Award Drivers\n\n\n\n\n\n\n\nRun full estimation\n# Load libraries\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(knitr)\n\n# Step 1: Load and preprocess data\nblueprinty &lt;- read_csv(\"C:/Users/krish/hamsavi/blog/project4/blueprinty.csv\") %&gt;%\n  mutate(\n    age_sq = age^2,\n    region = factor(region),\n    customer = as.integer(iscustomer)  # Fix here: use iscustomer\n  )\n\n# Step 2: Create design matrix and response\nX &lt;- model.matrix(~ age + age_sq + region + customer, data = blueprinty)\nY &lt;- blueprinty$patents\ninit_beta &lt;- rep(0, ncol(X))  # Initial guess for optimization\n\n# Step 3: Define Poisson log-likelihood function\npoisson_regression_likelihood &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta\n  lambda &lt;- exp(eta)\n  loglik &lt;- sum(Y * log(lambda) - lambda - lgamma(Y + 1))\n  return(-loglik)\n}\n\n# Step 4: Optimize\nmle_result &lt;- optim(\n  par = init_beta,\n  fn = poisson_regression_likelihood,\n  Y = Y,\n  X = X,\n  hessian = TRUE,\n  method = \"BFGS\"\n)\n\n# Step 5: Extract estimates and SEs\nbeta_hat &lt;- mle_result$par\nhessian &lt;- mle_result$hessian\n\n# Check Hessian validity\nif (!is.null(hessian) && is.matrix(hessian)) {\n  var_cov &lt;- solve(hessian)\n  se_hat &lt;- sqrt(diag(var_cov))\n} else {\n  se_hat &lt;- rep(NA, length(beta_hat))\n  warning(\"Hessian is invalid; SEs not computed.\")\n}\n\n# Step 6: Output results\nresults &lt;- tibble(\n  Term = colnames(X),\n  Estimate = round(beta_hat, 4),\n  `Std. Error` = round(se_hat, 4)\n)\n\nkable(results, caption = \"Poisson Regression Coefficient Estimates and Standard Errors\")\n\n\n\nPoisson Regression Coefficient Estimates and Standard Errors\n\n\nTerm\nEstimate\nStd. Error\n\n\n\n\n(Intercept)\n-0.1257\n0.1122\n\n\nage\n0.1158\n0.0064\n\n\nage_sq\n-0.0022\n0.0001\n\n\nregionNortheast\n-0.0246\n0.0434\n\n\nregionNorthwest\n-0.0348\n0.0529\n\n\nregionSouth\n-0.0054\n0.0524\n\n\nregionSouthwest\n-0.0378\n0.0472\n\n\ncustomer\n0.0607\n0.0321\n\n\n\n\n\n\n\nShow glm() regression results\n# Load necessary libraries\nlibrary(broom)\nlibrary(knitr)\n\n# Fit Poisson regression using glm()\nglm_model &lt;- glm(\n  patents ~ age + I(age^2) + region + customer,\n  data = blueprinty,\n  family = poisson(link = \"log\")\n)\n\n# Tidy up results and round for presentation\nglm_results &lt;- tidy(glm_model) %&gt;%\n  mutate(\n    Estimate = round(estimate, 4),\n    `Std. Error` = round(std.error, 4),\n    `z value` = round(statistic, 2),\n    `p-value` = round(p.value, 4)\n  ) %&gt;%\n  select(term, Estimate, `Std. Error`, `z value`, `p-value`)\n\n# Output as a formatted table\nkable(glm_results, caption = \"Poisson Regression Results Using glm()\")\n\n\n\nPoisson Regression Results Using glm()\n\n\nterm\nEstimate\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n-0.5089\n0.1832\n-2.78\n0.0055\n\n\nage\n0.1486\n0.0139\n10.72\n0.0000\n\n\nI(age^2)\n-0.0030\n0.0003\n-11.51\n0.0000\n\n\nregionNortheast\n0.0292\n0.0436\n0.67\n0.5037\n\n\nregionNorthwest\n-0.0176\n0.0538\n-0.33\n0.7438\n\n\nregionSouth\n0.0566\n0.0527\n1.07\n0.2828\n\n\nregionSouthwest\n0.0506\n0.0472\n1.07\n0.2839\n\n\ncustomer\n0.2076\n0.0309\n6.72\n0.0000\n\n\n\n\n\n\n\nThe Poisson regression estimates the expected number of patents awarded as a function of firm age, region, and whether the firm is a Blueprinty customer.\n\n\n\nCustomer (Estimate = 0.2076, p &lt; 0.001)\nBeing a Blueprinty customer is associated with a significantly higher rate of patent awards.\nInterpreting the coefficient:\n\\[\\exp(0.2076) \\approx 1.23\\]\nCustomers have about 23% more patents, on average, than non-customers, holding other factors constant.\nAge and Age² (Both p &lt; 0.001)\nThe relationship between firm age and patent success is non-linear:\n\nThe positive coefficient on age suggests older firms initially file more patents.\n\nThe negative coefficient on age² implies diminishing returns with age — a concave-down relationship.\n\nRegion Variables (All p &gt; 0.05)\nNone of the regional dummies are statistically significant. This suggests that region is not a strong predictor of patent success in this model.\nIntercept (Estimate = -0.5089, p = 0.0055)\nRepresents the log expected count of patents for a non-customer firm in the baseline region (e.g., Midwest), with age and age² = 0. Mostly useful as a baseline level.\n\n\n\n\n\n\n\n\n\n\n\n\nConclusion\n\n\n\n\n\nTo understand the practical effect of Blueprinty’s software on patent success, we compute predicted patent counts under two scenarios:\n\nX₀: Each firm is treated as a non-customer (customer = 0)\nX₁: Each firm is treated as a customer (customer = 1)\n\nUsing the estimated Poisson regression model, we compute predicted values (y_pred_0 and y_pred_1) and then take the average difference.\n\nEstimate average effect of Blueprinty’s software using counterfactuals\n# Make sure glm_result exists (run glm before this!)\nif (!exists(\"glm_result\")) {\n  glm_result &lt;- glm(\n    patents ~ age + I(age^2) + region + iscustomer,\n    data = blueprinty,\n    family = poisson(link = \"log\")\n  )\n}\n\n# Step 1: Create counterfactual design matrices\nX_0 &lt;- model.matrix(~ age + I(age^2) + region + iscustomer,\n                    data = blueprinty %&gt;% mutate(iscustomer = 0))\nX_1 &lt;- model.matrix(~ age + I(age^2) + region + iscustomer,\n                    data = blueprinty %&gt;% mutate(iscustomer = 1))\n\n# Step 2: Predict lambda (expected number of patents)\nlambda_0 &lt;- exp(X_0 %*% coef(glm_result))\nlambda_1 &lt;- exp(X_1 %*% coef(glm_result))\n\n# Step 3: Compute average difference\naverage_effect &lt;- mean(lambda_1 - lambda_0)\n\n# Step 4: Display result\naverage_effect\n\n[1] 0.7927681\n\n\nThe analysis reveals that, on average, firms using Blueprinty’s software are predicted to receive approximately 0.79 more patents over a 5-year period compared to if they were not customers — holding all other factors (such as age and region) constant.\nThis suggests that Blueprinty’s product is associated with a substantial and positive effect on patent success. While this estimate supports the marketing team’s claims, it is important to note that the analysis is observational in nature and does not account for unmeasured confounders (e.g., firm size, innovation strategy), which could influence the result.\n\n\n\n\n\n\n\n\n\n\nAirBnB Case Study\n\n\n\n\n\n\n\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis & Cleaning\n\n\n\n\n\n\n\nLoad and explore AirBnB dataset\nlibrary(tidyverse)\nlibrary(knitr)\n\n# Load data\nairbnb &lt;- read_csv(\"airbnb.csv\")\n\n# Select relevant variables and drop rows with NAs\nairbnb_clean &lt;- airbnb %&gt;%\n  select(number_of_reviews, room_type, price, bathrooms, bedrooms,\n         review_scores_cleanliness, review_scores_location, review_scores_value,\n         instant_bookable, days) %&gt;%\n  drop_na()\n\n# Nicely formatted summary statistics for number_of_reviews\nairbnb_clean %&gt;%\n  summarise(\n    Min = min(number_of_reviews),\n    Q1 = quantile(number_of_reviews, 0.25),\n    Median = median(number_of_reviews),\n    Mean = mean(number_of_reviews),\n    Q3 = quantile(number_of_reviews, 0.75),\n    Max = max(number_of_reviews)\n  ) %&gt;%\n  kable(caption = \"Summary Statistics: Number of Reviews\")\n\n\n\nSummary Statistics: Number of Reviews\n\n\nMin\nQ1\nMedian\nMean\nQ3\nMax\n\n\n\n\n1\n3\n8\n21.17089\n26\n421\n\n\n\n\n\nLoad and explore AirBnB dataset\n# Nicely formatted table of room types\nairbnb_clean %&gt;%\n  count(room_type, name = \"Count\") %&gt;%\n  kable(caption = \"Room Type Frequency Table\")\n\n\n\nRoom Type Frequency Table\n\n\nroom_type\nCount\n\n\n\n\nEntire home/apt\n15543\n\n\nPrivate room\n13773\n\n\nShared room\n844\n\n\n\n\n\n\n\nPlot EDA graphs\n# Histogram of number_of_reviews\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(fill = \"#2c7fb8\", color = \"white\", bins = 50) +\n  labs(title = \"Distribution of Number of Reviews\",\n       x = \"Number of Reviews\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\nDistribution of Number of Reviews\n\n\n\n\n\n\nBoxplot by Room Type\n# Boxplot of reviews by room_type\nggplot(airbnb_clean, aes(x = room_type, y = number_of_reviews, fill = room_type)) +\n  geom_boxplot() +\n  labs(title = \"Number of Reviews by Room Type\",\n       x = \"Room Type\", y = \"Number of Reviews\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nNumber of Reviews by Room Type\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Model\n\n\n\n\n\n\n\nFit and display Poisson regression results\nlibrary(broom)\nlibrary(knitr)\n\n# Fit Poisson regression model\npoisson_model &lt;- glm(\n  number_of_reviews ~ room_type + price + bathrooms + bedrooms + \n    review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable + days,\n  data = airbnb_clean,\n  family = poisson(link = \"log\")\n)\n\n# Tidy the summary and format\ntidy(poisson_model) %&gt;%\n  mutate(\n    Estimate = round(estimate, 4),\n    `Std. Error` = round(std.error, 4),\n    `z value` = round(statistic, 2),\n    `p-value` = round(p.value, 4)\n  ) %&gt;%\n  select(term, Estimate, `Std. Error`, `z value`, `p-value`) %&gt;%\n  kable(caption = \"Poisson Regression Results: Number of Reviews\")\n\n\n\nPoisson Regression Results: Number of Reviews\n\n\nterm\nEstimate\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n3.4980\n0.0161\n217.40\n0.0000\n\n\nroom_typePrivate room\n-0.0105\n0.0027\n-3.85\n0.0001\n\n\nroom_typeShared room\n-0.2463\n0.0086\n-28.58\n0.0000\n\n\nprice\n0.0000\n0.0000\n-2.15\n0.0315\n\n\nbathrooms\n-0.1177\n0.0037\n-31.39\n0.0000\n\n\nbedrooms\n0.0741\n0.0020\n37.20\n0.0000\n\n\nreview_scores_cleanliness\n0.1131\n0.0015\n75.61\n0.0000\n\n\nreview_scores_location\n-0.0769\n0.0016\n-47.80\n0.0000\n\n\nreview_scores_value\n-0.0911\n0.0018\n-50.49\n0.0000\n\n\ninstant_bookableTRUE\n0.3459\n0.0029\n119.67\n0.0000\n\n\ndays\n0.0001\n0.0000\n129.76\n0.0000\n\n\n\n\n\n\n\n\n\n\n\nThe model reveals significant variation in review counts based on listing characteristics:\n\nRoom Type: Compared to an entire home, private and shared rooms tend to have different review patterns. Coefficients can be exponentiated to interpret as multiplicative changes.\nPrice: A higher price is associated with a lower number of reviews, likely reflecting reduced affordability.\nReview Scores: Cleanliness, location, and value ratings are positively associated with bookings — cleaner, well-located, and good-value properties tend to get more reviews.\nInstant Bookable: Listings marked as instantly bookable receive more reviews on average.\nDays Listed: The longer a property has been on the platform, the more reviews it accumulates — as expected.\n\nOverall, the Poisson model helps quantify how various features influence demand (proxied by review counts) on Airbnb."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#interpretation-of-poisson-regression-results",
    "href": "blog/project4/hw2_questions.html#interpretation-of-poisson-regression-results",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "The Poisson regression estimates the expected number of patents awarded as a function of firm age, region, and whether the firm is a Blueprinty customer.\n\n\n\nCustomer (Estimate = 0.2076, p &lt; 0.001)\nBeing a Blueprinty customer is associated with a significantly higher rate of patent awards.\nInterpreting the coefficient:\n\\[\\exp(0.2076) \\approx 1.23\\]\nCustomers have about 23% more patents, on average, than non-customers, holding other factors constant.\nAge and Age² (Both p &lt; 0.001)\nThe relationship between firm age and patent success is non-linear:\n\nThe positive coefficient on age suggests older firms initially file more patents.\n\nThe negative coefficient on age² implies diminishing returns with age — a concave-down relationship.\n\nRegion Variables (All p &gt; 0.05)\nNone of the regional dummies are statistically significant. This suggests that region is not a strong predictor of patent success in this model.\nIntercept (Estimate = -0.5089, p = 0.0055)\nRepresents the log expected count of patents for a non-customer firm in the baseline region (e.g., Midwest), with age and age² = 0. Mostly useful as a baseline level."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hamsavi Krishnan",
    "section": "",
    "text": "Here is a paragraph about me!\nIntroductions are often difficult, but here’s a little something about me. After graduating with a degree in commerce, specializing in financial accounting and audit, I worked in finance and assurance across industries such as healthcare, entertainment, IT, and technology. These experiences sharpened my critical analysis skills and ignited a deep interest in leveraging data to drive business strategies.\nCurrently, I’m pursuing a Master’s in Business Analytics at UC San Diego, where I’m focused on using data-driven insights to solve real-world problems and foster innovation. I’m eager to connect with like-minded professionals and explore opportunities to make meaningful contributions in the field of business analytics"
  }
]